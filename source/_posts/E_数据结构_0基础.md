---
title: 0数据结构基础
date: 2021-11-01 06:33:16
categories:
- E_数据结构
toc: true # 是否启用内容索引
---

《算法数据结构体系学习班》

# 1.面向对象

(1)面向过程与面向对象

面向过程：早期我们使用的是过程变成，即自己是执行者，执行代码。

面向对象：自己则变成了指挥者，从始至终都是自己去命令、调度其他资源完成任务。更加符合人思考习惯，从执行者变成指挥者。

(2)面向对象4大特性

软件编程就是将我们的思想转变成计算机能够识别的语言的过程。

面向对象是把一组数据结构和处理他们的方法组成对象。

抽象、封装、继承、多态

- 抽象：把具有相同行为的对象归为类
- 封装：通过封装隐藏类的内部细节
- 继承：通过继承使类得到泛化
- 多态：通过多态实现基于对象类型的动态分配

**面向对象四大特性**

抽象：**提高代码的扩展性、可维护性，降低复杂度**。对方法的具体实现进行隐藏，让调用者只需要关心方法

封装：**保护数据和隐藏信息**，访问权限控制。通过暴露有限的方法来达到保护数据的作用

继承：**解决代码复用问题，提升可维护性**。继承最大的作用就是用来实现更好的代码复用，减少重复代码。

多态：**提高代码的可扩展性和复用性**。需要编程语言提供特殊的语法机制，通过多态使代码变得更加灵活。“同一个事件发生在不同的对象上会产生不同的结果”

# 2.为什么大厂螺丝钉的岗位需要算法很牛逼人

算法是绝对代码能力和耐心的一种证明。算法是智力程度的良好证明。老的框架技术已经没办法筛查人才。

**算法是绝对代码能力和耐心的一种证明**

好公司考算法与数据结构的比重是比较大的，以前大公司考的现在比重越来越高，现在小公司以前不考的现在也开始考了。早期的程序员是非常在乎算法数据机构，比如阿波罗登月，飞船的控制程序内存不足1M，当时那批老派程序员以极强的算法与数据结构把有限的资源榨取到极致，充分发挥自己在算法与数据结构的设计和能力。在一个很吃紧的资源下也能完成很复杂的任务。

大公司的面经经过记忆性的知识，是可以基本应付的，但是算法不行。你需要理解基础算法与数据结构，还要触类旁通，举一反三，逻辑推导。所以我们国内开始考察这些方向，同时美国外国公司早就考过算法了。因为你进入到工作岗位，记忆性的知识是可以查文档的，你是可以现场现学的，哪怕是面向google编程。但是算法不行，因为门槛比较高。

国外公司只考算法与数据结构，是因为杜绝了其他方向是重要的，或者说对于一个即将进入职场，每天可以查询网络资料的人，记忆性的东西没那么重要。有一个段子，若干年之前，google招了一个接线员，宾夕法尼亚的法律系博士，这行业内卷到这个程度？google招聘精英基本是传统，一个电话接线员都招这么贵，为什么？google招聘两个员工，A员工比B员工的代码性能提升5%-7%，到代码部署到用户真实使用的场景下，带来的收益远远超过招聘成本本身。所以坊间流传着一句话：最贵的就是最省的。可能你觉得美国计算机专业前三的名校的博士，每年给那呢么多钱，然后也写很简单的业务，你觉得是浪费？但是不是的。

招精英员工即最贵的就是最省的。代码性能提升5%到10%，可以省下昂贵的开销。
以前是糙快猛，现在公司板块领域瓜分完了，就进入仔细耕耘，好好迭代，优化代码，提升性能。

**算法是智力程度的良好证明**

刷题，刷题，刷题。从隐隐理解算法，到真正写出算法，不是一般人能坚持的。如果对算法或代码面试稍微了解的人，都知道，公司实际出题目可能是在白纸或编辑器上写出代码的，有些面试官可能因为你一点点边界条件没考虑好，就直接扣分或让你走人都有可能。

**老的框架技术已经没办法筛查人才**

技术知识可以通过记忆性的东西还原，但是算法不行，必须需要理解并掌握核心思想。

# 3.经典排序算法

**算法分类**

- 内部排序(交叉选轨迹)

  交换：冒泡、快排

  插入：直接插入、希尔排序

  选择:简单选择、堆排序

  归并排序

  基数排序

- 外部排序

![image-20220113223656269](/img/image-20220113223656269.png)

# 4.topK问题

**100亿数据找出最大的1000个数字（top K问题）**

***对于海量数据处理，思路基本上是：必须分块处理，然后再合并起来。***

**a.理论方法：**

1. 全部排序
2. 局部淘汰法
3. 分治法
4. Hash法

**1.全部排序**

**最容易想到的方法是将数据全部排序**。该方法并不高效，因为题目的目的是寻找出最大的10000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功。

**2.局部淘汰法**

用一个容器保存前10000个数，然后将剩余的所有数字一一与容器内的最小数字相比，如果所有后续的元素都比容器内的10000个数还小，那么容器内这个10000个数就是最大10000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O（n+m^2），其中m为容器的大小。

这个容器可以用（小顶堆）最小堆来实现。我们知道完全二叉树有几个非常重要的特性，就是假如该二叉树中总共有N个节点，那么该二叉树的深度就是log2N，对于小顶堆来说移动根元素到 底部或者移动底部元素到根部只需要log2N，相比N来说时间复杂度优化太多了（1亿的logN值是26-27的一个浮点数）。基本的思路就是先从文件中取出1000个元素构建一个小顶堆数组k，然后依次对剩下的100亿-1000个数字进行遍历m，如果m大于小顶堆的根元素，即k[0]，那么用m取代k[0]，对新的数组进行重新构建组成一个新的小顶堆。这个算法的时间复杂度是O((100亿-1000)log(1000))，即O((N-M)logM)，空间复杂度是M

这个算法优点是性能尚可，空间复杂度低，IO读取比较频繁，对系统压力大。

**3.分治法**

a、将100亿个数据分为1000个大分区，每个区1000万个数据

b、每个大分区再细分成100个小分区。总共就有1000*100=10万个分区

c、计算每个小分区上最大的1000个数。

> 为什么要找出每个分区上最大的1000个数？举个例子说明，全校高一有100个班，我想找出全校前10名的同学，很傻的办法就是，把高一100个班的同学成绩都取出来，作比较，这个比较数据量太大了。应该很容易想到，班里的第11名，不可能是全校的前10名。也就是说，不是班里的前10名，就不可能是全校的前10名。因此，只需要把每个班里的前10取出来，作比较就行了，这样比较的数据量就大大地减少了。我们要找的是100亿中的最大1000个数，所以每个分区中的第1001个数一定不可能是所有数据中的前1000个。

d、合并每个大分区细分出来的小分区。每个大分区有100个小分区，我们已经找出了每个小分区的前1000个数。将这100个分区的1000*100个数合并，找出每个大分区的前1000个数。

e、合并大分区。我们有1000个大分区，上一步已找出每个大分区的前1000个数。我们将这1000*1000个数合并，找出前1000.这1000个数就是所有数据中最大的1000个数。

（a、b、c为map阶段，d、e为reduce阶段）

**4.Hash法**

如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数。

**b.实战解法**

1.立刻就能想到的解法:快排

2.O(n) 时间复杂度的方法：快排的 partition 划分思想可以用于计算某个位置的数值等问题。虽然时间复杂度是 O(n) ，但是缺点也很明显，最主要的就是内存问题，在海量数据的情况下，我们很有可能没办法一次性将数据全部加载入内存，这个时候这个方法就无法完成使命了

3.利用分布式思想处理海量数据

4.利用最经典的方法，一台机器也能处理海量数据

[leecode40](https://leetcode.cn/problems/zui-xiao-de-kge-shu-lcof/solution/tu-jie-top-k-wen-ti-de-liang-chong-jie-fa-you-lie-/)

其实提到 Top K 问题，最经典的解法还是利用堆。

维护一个大小为 K 的小顶堆，依次将数据放入堆中，当堆的大小满了的时候，只需要将堆顶元素与下一个数比较：如果大于堆顶元素，则将当前的堆顶元素抛弃，并将该元素插入堆中。遍历完全部数据，Top K 的元素也自然都在堆里面了。

当然，如果是求前 K 个最小的数，只需要改为大顶堆即可



**MapReduce**

[一文读懂MapReduce原文](https://juejin.cn/post/6844903812784717831)

MapReduce 是一个高性能的分布式计算框架，用于大规模数据集（大于1TB）的并行运算。它极大的方便编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。MapReduce分为Map(映射)和Reduce(化简)两个阶段，是在HDFS存储数据的基础上，将一个较大的计算任务(job)分解成若干小任务(task)，每个小任务都由一个Map任务(task)来计算（这个Map尽量在数据所在节点上完成计算），然后再将每个Map的计算结果由一个或多个Reduce任务(task)合并，得到最终的结果。

# 5.常见算法-动态规划算法

动态规划是算法设计中的一种方法，一种算法设计思想。它将一个问题分解为相互重叠的子问题，通过反复求解子问题，来解决原来的问题。

## **举例算法题：爬楼梯**

假设你正在爬楼梯。需要 n 阶你才能到达楼顶。
每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？
注意：给定 n 是一个正整数。

**示例 1：**

```html
输入： 2
输出： 2
解释： 有两种方法可以爬到楼顶。
1.  1 阶 + 1 阶
2.  2 阶
```

**示例 2：**

```html
输入： 3
输出： 3
解释： 有三种方法可以爬到楼顶。
1.  1 阶 + 1 阶 + 1 阶
2.  1 阶 + 2 阶
3.  2 阶 + 1 阶
```

**解题思路：**

- 爬到第n阶可以在第n-1阶爬1个台阶，或者在第n-2阶爬2个台阶.
- F(n)=F(n-1)+F(n-2)。
- 使用动态规划。

**解题步骤：**

- 定义子问题：F(n)=F(n-1)+F(n-2)。
- 反复执行：从2循环到n,执行上述公式。

**解体答案：**

**1、时间复杂度O(n)，空间复杂度O(n)**

```js
var climbStairs = function(n){
    //边界条件
    if(n < 2){ return 1; }
    const dp = [1, 1]; //记录第n阶有多少种方法
    for(let i = 2; i<=n; i=+1){
        dp[i] = dp[i-1]+dp[i-2];
    }
    console.log(dp);
    return dp[n];
}
```

**2、时间复杂度O(n) 空间复杂度O(1)**

```js
var climbStairs = function(n){
    //边界条件
    if(n < 2){ return 1; }
    let dp0 = 1;
    let dp1 = 1
    for(let i = 2; i<=n; i=+1){
        const temp = dp0;
        dp0 = dp1;
        dp1 = dp1 + temp;
    }
    return dp1;
}
```

# 常见算法-回溯算法

回溯算法是算法设计中的一种方法，算法的一种设计思想。是一种渐进式寻找并构建问题解决方式的策略。回溯算法会从一个可能的动作开始解决问题，如果不行，就回溯并选择另一个动作，直到将问题解决。

**什么问题适合用回溯算法解决：**
有很多路。
这些路里，有死路，也有出路。
通常需要递归来模拟所有的路。

**例如：全排列问题：**
用递归模拟出所有情况。
遇到包含重复元素的情况，就回溯（不要在遍历）。
收集所有到达递归终点的情况，并返回。

## **举例算法题一：全排列**

给定一个 没有重复 数字的序列，返回其所有可能的全排列。
**示例:**
**输入:** [1,2,3]
**输出:**

```json
[
  [1,2,3],
  [1,3,2],
  [2,1,3],
  [2,3,1],
  [3,1,2],
  [3,2,1]
]
```

**解题思路：**

前提要求：1、所有排列情况；2、没有重复元素

- 有出路，有死路
- 考虑使用回溯算法

**解题步骤：**

1、用递归模拟出所有情况。
2、遇到包含重复元素的情况，就回溯（不在递归下去）。
3、收集所有到达终点的情况，并返回。

**解题答案：**

```js
var permute = function(nums){
    const res = []; //所有出路
    const backrack = (path) =>{ //递归
        //收集满足要求的排列组合,递归的终点
        if(path.length === nums.length){
            res.push(path);
            return;
        }
        nums.forEach(n => {
            if(path.includes(n)){ return;} //一些路是死路,就回溯
            backrack(path.concat(n));  //下一次递归加到数组里面
        });
    } 
    backrack([]); //[1,2,3]
    return res;
}

var arr =  [1,2,3,4]
console.log(permute(arr))
```

算法分析：

时间复杂度最复杂的，嵌套的for循环，是 O(n!),n!= 1*2*3#…(n-1)*n; 
空间复杂度是，输出的数组用到递归（堆栈），递归的深度N：O(n)。

## **举例算法题二：子集**

给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的子集（幂集）。
解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。

**示例 1：**

```html
输入：nums = [1,2,3]
输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]]
```

**示例 2：**

```html
输入：nums = [0]
输出：[[],[0]]
```

**提示：**

- `1 <= nums.length <= 10`
- `-10 <= nums[i] <= 10`
- `nums` 中的所有元素 **互不相同**

解题思路：

要求：1、所有的子集；2、没有重复元素和子集
有出路，有死路
考虑使用回溯算法

**解题步骤：**

1、用递归模拟出所有情况。写递归函数遍历每一个数。
2、保证接的数字都是后面的数字。
3、收集所有到达递归终点的情况，并返回。

解题答案：

```js
var subsets = function(nums){
    const res = []; //用来最为最终输出的大数组
    const backtrack = (path, l, start) =>{ //backtrack回溯的意思,参数是路径、长度、下标
        if(path.length === l){ //收集到终点的情况
            res.push(path);
            return;
        }
        for(let i = start; i <= nums.length; i += 1){
            backtrack(path.concat(nums[i]), l, i + 1);
        }
    }
    for(let i = 0; i <= nums.length; i += 1){
        backtrack([],i,0) //参数是路径、长度、下标
    }
    return res;
}

var arr =  [1,2,3]
console.log(subsets(arr))
```

**算法分析：**

时间复杂度:O(2^N),因为每个元素都有可能有两种可能（存在或不存在）；
空间复杂度是O(N) 递归堆栈放的临时变量。

## 其他回溯法

[最全排列组合问题](https://blog.csdn.net/bitcarmanlee/article/details/114500993)

# 常见算法-分而治之算法

分而治之是算法设计中的一种方法，算法的一种设计思想。它将一个问题分成多个和原问题相似的小问题，递归解决小问题，再将结果合并一解决原来的问题。

**使用场景一： 归并排序**

分：把数组从中间一分为二。
解：递归地对两个子数组进行归并排序。
合：合并有序子数组。

**使用场景二： 快速排序**

分：选基准，按基准把数组分成两个子数组。
解：递归地对两个子数组进行快速排序。
合：对两个子数组进行合并。

## **举例算法题一：猜数字大小**

**猜数字游戏的规则如下：**

每轮游戏，我都会从 1 到 n 随机选择一个数字。 请你猜选出的是哪个数字。
如果你猜错了，我会告诉你，你猜测的数字比我选出的数字是大了还是小了。
你可以通过调用一个预先定义好的接口 int guess(int num) 来获取猜测结果，返回值一共有 3 种可能的情况（-1，1 或 0）：

-1：我选出的数字比你猜的数字小 pick < num 1：我选出的数字比你猜的数字大 pick > num
0：我选出的数字和你猜的数字一样。恭喜！你猜对了！pick == num
返回我选出的数字。

**示例 1：**
输入：n = 10, pick = 6
输出：6

**示例 2：**
输入：n = 1, pick = 1
输出：1

**示例 3：**
输入：n = 2, pick = 1
输出：1

**示例 4：**
输入：n = 2, pick = 2
输出：2

**提示：**
1 <= n <= 2^31 – 1
1 <= pick <= n

解题思路

分：计算中间元素，分割数组。
解:递归地在较大或者较小数组进行二分搜索。
合：不需要此步，因为在子数组中搜到就返回了。

**解题答案**

```js
var guessNumber = function(n){
    const rec = (low,high) =>{
        if(low > high){ return }
        const mid = Math.floor((low+high) / 2);
        const res = guess(mid);
        if(res === 0){
            return mid;
        }else if(res === 1){
            return rec(mid + 1,high);
        }else{
            return rec(1, mid - 1);
        }
    }
    return rec(1,n);
}
```

**解题分析**

时间复杂度 O(logn)，空间复杂度 O(logn)

## **举例算法题二：翻转二叉树**

翻转一棵二叉树。
**示例：**
**输入：**

```js
     4
   /   \
  2     7
 / \   / \
1   3 6   9
```

**输出：**

```js
     4
   /   \
  7     2
 / \   / \
9   6 3   1
```

解题思路：

- 先反转左右子树，再将子树换个位置。
- 符合“分、解、和”特性。
- 考虑用分而治之来做。

解题步骤：

分：获取左右子树。
解：递归地翻转左右子树。
合：将翻转后的左右子树换个位置放到根节点上。

解题答案：

```js
var invertTree = function(root){
    if(!root){ return null; }
    return {
        val: root.val,
        left: invertTree(root.right),
        right: invertTree(root.left)
    }
}
```

解题分析：

时间复杂度O(n)，空间复杂度 O(n)。

## **举例算法题三：相同的树**

给你两棵二叉树的根节点 p 和 q ，编写一个函数来检验这两棵树是否相同。
如果两个树在结构上相同，并且节点具有相同的值，则认为它们是相同的。

**示例 1：**

![分而治之算法-贺鹏飞的博客](https://www.hepengfei.net/wp-content/uploads/2021/04/ex1.jpg)

```
输入：p = [1,2,3], q = [1,2,3]
输出：true
```

**示例 2：**

![分而治之算法-贺鹏飞的博客](https://www.hepengfei.net/wp-content/uploads/2021/04/ex2.jpg)

```
输入：p = [1,2], q = [1,null,2]
输出：false
```

**示例 3：**

![分而治之算法-贺鹏飞的博客](https://www.hepengfei.net/wp-content/uploads/2021/04/ex3.jpg)

```
输入：p = [1,2,1], q = [1,1,2]
输出：false
```

**提示：**

- 两棵树上的节点数目都在范围 `[0, 100]` 内
- `-104 <= Node.val <= 104`

解题思路：

- 两棵树：根节点的值相同，左子树相同，右子树相同
- 符合“分、解、和”特性。
- 考虑用分而治之来做。

**解题步骤：**

分：获取两个树的左子树和右子树。
解：递归地判断两个数的左子树是否相同，右子树是否相同。
合：将上述结果合并，如果根节点的值也相同，树就相同。

解题答案：

```js
var inSameTree = function(p,q){
    if(!p && !q){ return true} //如果两个都为空
    if( p && q && p.val === q.val && 
        inSameTree(p.left,q.left )&& 
        inSameTree(p.right,q.right)
     ){
         return true;
     }
     return false;
}
```

## **举例算法题四：对称二叉树**

给定一个二叉树，检查它是否是镜像对称的。
例如，二叉树 `[1,2,2,3,4,4,3]` 是对称的。

```js
    1
   / \
  2   2
 / \ / \
3  4 4  3
```

但是下面这个 `[1,2,2,null,3,null,3]` 则不是镜像对称的:

```js
    1
   / \
  2   2
   \   \
   3    3
```

解题思路：

- 转化为：左右子树是否镜像。
- 分解为：树1的左子树和树2的右子树是否镜像，树1的右子树和树2的左子树是否镜像。
- 符合“分、解、和”特性，考虑用分而治之来做。

解题步骤：

分：获取两个树的左子树和右子树。
解：递归地判断树1的左子树和树2的右子树是否镜像，树1的右子树和树2的左子树是否镜像。
合：如果上述都成立，且根节点值也相同，两个树就镜像。

解题答案：

```js
var isSymmetric = function(root){
    if(!root) return true;
    const isMirror = (l, r) => {
        if(!l && !r) return true;
        if(l && r && l.val === r.val &&
            isMirror(l.left, r.right)&&
            isMirror(l.right, r.left)
          ){
              return true;
          }
          return false;
    }
    return isMirror(root.left, root.right);
}
```

解题分析：

时间复杂度O(n)，空间复杂度 O(LogN)和O(n)。

# 常见算法-贪心算法

贪心算法是算法设计中的一种方法，算法的一种设计思想，期盼通过每个阶段的局部最优选择，从而达到全局的最优，结果并不一定是最优。

## **举例算法题一：分发饼干**

假设你是一位很棒的家长，想要给你的孩子们一些小饼干。但是，每个孩子最多只能给一块饼干。

对每个孩子 i，都有一个胃口值 g[i]，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 j，都有一个尺寸 s[j] 。如果 s[j] >= g[i]，我们可以将这个饼干 j 分配给孩子 i ，这个孩子会得到满足。你的目标是尽可能满足越多数量的孩子，并输出这个最大数值。

**示例 1:**

```plane
输入: g = [1,2,3], s = [1,1]
输出: 1
解释:
你有三个孩子和两块小饼干，3个孩子的胃口值分别是：1,2,3。
虽然你有两块小饼干，由于他们的尺寸都是1，你只能让胃口值是1的孩子满足。
所以你应该输出1。
```

**示例 2:**

```plane
输入: g = [1,2], s = [1,2,3]
输出: 2
解释:
你有两个孩子和三块小饼干，2个孩子的胃口值分别是1,2。
你拥有的饼干数量和尺寸都足以让所有孩子满足。
所以你应该输出2.
```

**提示：**

- `1 <= g.length <= 3 * 104`
- `0 <= s.length <= 3 * 104`
- `1 <= g[i], s[j] <= 231 - 1`

解题思路：

- 局部最优：既能满足孩子，还消耗最少。
- 先将“较小的饼干”分给“胃口最小”的孩子。

解题步骤：

- 对饼干数组和胃口数组升序排序。
- 遍历饼干数组，找到能满足第一个孩子的饼干。
- 然后继续遍历饼干数组，找到满足第二、三、……、n个孩子的饼干。

解题答案：

```js
var findContentChildren = function(g,s){
    //升序排序
    const sortFunc = function(a,b){
        return a - b; //实现降序 b - a
    }
    g.sort(sortFunc);
    s.sort(sortFunc);
    let i = 0;
    s.forEach(n => {
        if(n >= g[i]){
            i += 1;
        }
    });
    return i;
}
```

## **举例算法题二：买卖股票的最佳时机 II**

给定一个数组 prices ，其中 prices[i] 是一支给定股票第 i 天的价格。
设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。
注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。

**示例 1:**

```plane
输入: prices = [7,1,5,3,6,4]
输出: 7
解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。
     随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。
```

**示例 2:**

```plane
输入: prices = [1,2,3,4,5]
输出: 4
解释: 在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。
     注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出。因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。
```

**示例 3:**

```plane
输入: prices = [7,6,4,3,1]
输出: 0
解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。
```

**提示：**

- `1 <= prices.length <= 3 * 104`
- `0 <= prices[i] <= 104`

解题思路：

- 前提：上帝视角，知道未来的价格。
- 局部最优：见好就收，见差就不动，不做任何长远打算。

解题步骤：

- 新建一个变量，用来统计总利润。
- 遍历价格数组，如果当前价格比昨天高，就在昨天买，今天卖，否组就不交易。
- 遍历结束后，返回所有利润之和。

解题答案：

```js
var maxProfit = function(prices){
    let profit = 0; //利润
    for(let i = 1; i < prices.length; i += 1){
        if(prices[i] > prices[i - 1]){ //当前价格大于昨天价格
            profit += prices[i] - prices[i - 1]
        }
    }
    return profit;
}

var prices = [7,1,5,3,6,4]
console.log(maxProfit(prices)) //7

var prices = [1,2,3,4,5]
console.log(maxProfit(prices)) //4

var prices = [7,6,4,3,1]
console.log(maxProfit(prices)) //0
```

解题分析：

时间复杂度 有一个for循环 O(n) ，空间复杂度 O(1)。

# 6.LRU算法

LRU算法全称是最近最少使用算法（Least Recently Use），广泛的应用于缓存机制中。当缓存使用的空间达到上限后，就需要从已有的数据中淘汰一部分以维持缓存的可用性，而淘汰数据的选择就是通过LRU算法完成的。

LRU算法的基本思想是基于局部性原理的时间局部性：

> 如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。

所以顾名思义，LRU算法会选出最近最少使用的数据进行淘汰。

## 原理

一般来讲，LRU将访问数据的顺序或时间和数据本身维护在一个容器当中。当访问一个数据时：

1. 该数据不在容器当中，则设置该数据的优先级为最高并放入容器中。
2. 该数据在容器当中，则更新该数据的优先级至最高。

当数据的总量达到上限后，则移除容器中优先级最低的数据。下图是一个简单的LRU原理示意图：

<img src="/img/image-20220605095455588.png" alt="image-20220605095455588" style="zoom:67%;" />

如果我们按照`7 0 1 2 0 3 0 4`的顺序来访问数据，且数据的总量上限为3，则如上图所示，LRU算法会依次淘汰`7 1 2`这三个数据。

## 朴素的LRU算法

那么我们现在就按照上面的原理，实现一个朴素的LRU算法。下面有三种方案：

1. 基于数组

   方案：为每一个数据附加一个额外的属性——时间戳，当每一次访问数据时，更新该数据的时间戳至当前时间。当数据空间已满后，则扫描整个数组，淘汰时间戳最小的数据。

   不足：维护时间戳需要耗费额外的空间，淘汰数据时需要扫描整个数组。

2. 基于长度有限的双向链表

   方案：访问一个数据时，当数据不在链表中，则将数据插入至链表头部，如果在链表中，则将该数据移至链表头部。当数据空间已满后，则淘汰链表最末尾的数据。

   不足：插入数据或取数据时，需要扫描整个链表。

3. 基于双向链表和哈希表

   方案：为了改进上面需要扫描链表的缺陷，配合哈希表，将数据和链表中的节点形成映射，将插入操作和读取操作的时间复杂度从O(N)降至O(1)

### **基于双向链表 + 哈希表实现LRU**

下面我们就基于双向链表和哈希表实现一个LRU算法

```
public class LRUCache {
    private int size; // 当前容量
    private int capacity; // 限制大小
    private Map<Integer, DoubleQueueNode> map; // 数据和链表中节点的映射
    private DoubleQueueNode head; // 头结点 避免null检查
    private DoubleQueueNode tail; // 尾结点 避免null检查
    
    public LRUCache(int capacity) {
        this.capacity = capacity;
        this.map = new HashMap<>(capacity);
        this.head = new DoubleQueueNode(0, 0);
        this.tail = new DoubleQueueNode(0, 0);
        this.head.next = tail;
    }

    public Integer get(Integer key) {

        DoubleQueueNode node = map.get(key);
        if (node == null) {
            return null;
        }

        // 数据在链表中，则移至链表头部
        moveToHead(node);

        return node.val;
    }

    public Integer put(Integer key, Integer value) {

        Integer oldValue;
        DoubleQueueNode node = map.get(key);
        if (node == null) {
            // 淘汰数据
            eliminate();
            // 数据不在链表中，插入数据至头部
            DoubleQueueNode newNode = new DoubleQueueNode(key, value);
            DoubleQueueNode temp = head.next;
            head.next = newNode;
            newNode.next = temp;
            newNode.pre = head;
            temp.pre = newNode;
            map.put(key, newNode);
            size++;
            oldValue = null;
        } else {
            // 数据在链表中，则移至链表头部
            moveToHead(node);
            oldValue = node.val;
            node.val = value;
        }
        return oldValue;
    }

    public Integer remove(Integer key) {
        DoubleQueueNode deletedNode = map.get(key);
        if (deletedNode == null) {
            return null;
        }
        deletedNode.pre.next = deletedNode.next;
        deletedNode.next.pre = deletedNode.pre;
        map.remove(key);
        return deletedNode.val;
    }
    
    // 将节点插入至头部节点
    private void moveToHead(DoubleQueueNode node) {
        node.pre.next = node.next;
        node.next.pre = node.pre;
        DoubleQueueNode temp = head.next;
        head.next = node;
        node.next = temp;
        node.pre = head;
        temp.pre = node;
    }

    private void eliminate() {
        if (size < capacity) {
            return;
        }
        
        // 将链表中最后一个节点去除
        DoubleQueueNode last = tail.pre;
        map.remove(last.key);
        last.pre.next = tail;
        tail.pre = last.pre;
        size--;
        last = null;
    }
}

// 双向链表节点
class DoubleQueueNode {
    int key;
    int val;
    DoubleQueueNode pre;
    DoubleQueueNode next;
    public DoubleQueueNode(int key, int val) {
        this.key = key;
        this.val = val;
    }
}
```

基本上就是把上述LRU算法思路用代码实现了一遍，比较简单，只需要注意一下pre和next两个指针的指向和同步更新哈希表，put()和get()操作的时间复杂度都是O(1)，空间复杂度为O(N)。

### 基于LinkedHashMap实现的LRU

其实我们可以直接根据JDK给我们提供的LinkedHashMap直接实现LRU。因为LinkedHashMap的底层即为双向链表和哈希表的组合，所以可以直接拿来使用。

```
public class LRUCache extends LinkedHashMap {

    private int capacity;

    public LRUCache(int capacity) {
        // 注意这里将LinkedHashMap的accessOrder设为true
        super(16, 0.75f, true);
        this.capacity = capacity;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return super.size() >= capacity;
    }
}

复制代码
```

默认LinkedHashMap并不会淘汰数据，所以我们重写了它的removeEldestEntry()方法，当数据数量达到预设上限后，淘汰数据，accessOrder设为true意为按照访问的顺序排序。整个实现的代码量并不大，主要都是应用LinkedHashMap的特性。

正因为LinkedHashMap这么好用，所以我们可以看到Dubbo的LRU缓存[LRUCache](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo%2Fblob%2F7a48fac84b14ac6a21c1bdfc5958705dd8dda84d%2Fdubbo-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fdubbo%2Fcommon%2Futils%2FLRUCache.java%23L23)也是基于它实现的。

## LRU算法优化

朴素的LRU算法已经能够满足缓存的要求了，但是还是有一些不足。当热点数据较多时，有较高的命中率，但是如果有偶发性的批量操作，会使得热点数据被非热点数据挤出容器，使得缓存受到了“污染”。所以为了消除这种影响，又衍生出了下面这些优化方法。

### LRU-K

LRU-K算法是对LRU算法的改进，将原先进入缓存队列的评判标准从访问一次改为访问K次，可以说朴素的LRU算法为LRU-1。

LRU-K算法有两个队列，一个是缓存队列，一个是数据访问历史队列。当访问一个数据时，首先先在访问历史队列中累加访问次数，当历史访问记录超过K次后，才将数据缓存至缓存队列，从而避免缓存队列被污染。同时访问历史队列中的数据可以按照LRU的规则进行淘汰。具体如下图所示：

<img src="/img/image-20220605095724949.png" alt="image-20220605095724949" style="zoom:67%;" />

下面我们来实现一个LRU-K缓存：

```
// 直接继承我们前面写好的LRUCache
public class LRUKCache extends LRUCache {
    
    private int k; // 进入缓存队列的评判标准
    private LRUCache historyList; // 访问数据历史记录

    public LRUKCache(int cacheSize, int historyCapacity, int k) {
        super(cacheSize);
        this.k = k;
        this.historyList = new LRUCache(historyCapacity);
    }

    @Override
    public Integer get(Integer key) {

        // 记录数据访问次数
        Integer historyCount = historyList.get(key);
        historyCount = historyCount == null ? 0 : historyCount;
        historyList.put(key, ++historyCount);

        return super.get(key);
    }

    @Override
    public Integer put(Integer key, Integer value) {

        if (value == null) {
            return null;
        }
        
        // 如果已经在缓存里则直接返回缓存中的数据
        if (super.get(key) != null) {
            return super.put(key, value);;
        }

        // 如果数据历史访问次数达到上限，则加入缓存
        Integer historyCount = historyList.get(key);
        historyCount = historyCount == null ? 0 : historyCount;
        if (historyCount >= k) {
            // 移除历史访问记录
            historyList.remove(key);
            return super.put(key, value);
        }
    }
}
```

一般来讲，当K的值越大，则缓存的命中率越高，但是也会使得缓存难以被淘汰。综合来说，使用LRU-2的性能最优。

### Two Queue

Two Queue可以说是LRU-2的一种变种，将数据访问历史改为FIFO队列。好处的明显的，FIFO更简易，耗用资源更少，但是相比LRU-2会降低缓存命中率。

<img src="/img/image-20220605095812371.png" alt="image-20220605095812371" style="zoom:80%;" />

```
// 直接继承LinkedHashMap
public class TwoQueueCache extends LinkedHashMap<Integer, Integer> {

    private int k; // 进入缓存队列的评判标准
    private int historyCapacity; // 访问数据历史记录最大大小
    private LRUCache lruCache; // 我们前面写好的LRUCache

    public TwoQueueCache(int cacheSize, int historyCapacity, int k) {
        // 注意这里设置LinkedHashMap的accessOrder为false
        super();
        this.historyCapacity = historyCapacity;
        this.k = k;
        this.lruCache = new LRUCache(cacheSize);
    }

    public Integer get(Integer key) {
        // 记录数据访问记录
        Integer historyCount = super.get(key);
        historyCount = historyCount == null ? 0 : historyCount;
        super.put(key, historyCount);
        return lruCache.get(key);
    }

    public Integer put(Integer key, Integer value) {

        if (value == null) {
            return null;
        }

        // 如果已经在缓存里则直接返回缓存中的数据
        if (lruCache.get(key) != null) {
            return lruCache.put(key, value);
        }

         // 如果数据历史访问次数达到上限，则加入缓存
        Integer historyCount = super.get(key);
        historyCount = historyCount == null ? 0 : historyCount;
        if (historyCount >= k) {
            // 移除历史访问记录
            super.remove(key);
            return lruCache.put(key, value);
        }

        return null;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return super.size() >= historyCapacity;
    }
}
```

这里直接继承LinkedHashMap，并且accessOrder默认为false，意为按照插入顺序进行排序，二者结合即为一个FIFO的队列。通过重写removeEldestEntry()方法来自动淘汰最早插入的数据。

### Multi Queue

相比于上面两种优化，Multi Queue的实现则复杂的多，顾名思义，Multi Queue是由多个LRU队列组成的。每一个LRU队列都有一个相应的优先级，数据会根据访问次数计算出相应的优先级，并放在该队列中。

<img src="/img/image-20220605095858203.png" alt="image-20220605095858203" style="zoom: 80%;" />

- 数据插入和访问：当数据首次插入时，会放入到优先级最低的Q0队列。当再次访问时，根据LRU的规则，会移至队列头部。当根据访问次数计算的优先级提升后，会将该数据移至更高优先级的队列的头部，并删除原队列的该数据。同样的，当该数据的优先级降低时，会移至低优先级的队列中。
- 数据淘汰：数据淘汰总是从最低优先级的队列的末尾数据进行，并将它加入到Q-history队列的头部。如果数据在Q-history数据中被访问，则重新计算该数据的优先级，并将它加入到相应优先级的队列中。否则就是按照LRU算法完全淘汰。

Multi Queue也可以看做是LRU-K的变种，将原来两个队列扩展为多个队列，好处就是无论是加入缓存还是淘汰缓存数据都变得更加细腻，但是会带来额外开销。

