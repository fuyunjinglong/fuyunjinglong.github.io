---
title: 0基础
date: 2021-11-04 06:33:16
categories:
- F_计算机网络
toc: true # 是否启用内容索引
---

**参考**

[小林coding](https://xiaolincoding.com/)

# 基础

## OSI7层网络模型

0.1也称为4层协议

- 会话层、表示层、应用层：http
- 传输层：tcp(面向连接，安全可靠有序，重试机制，慢，分段传输),udp(无连接，传输快，丢包，一次传输)
- 网络层：ip路由寻址，排队等待。ip + mac + 广播的方式 就能让你找到全世界所有的计算机的位置
- 物理层、数据链路层：物理层是物理连接介质，如光纤、双绞线。数据链路层是二进制数据也就是比特流进行分组。

![image-20211213065416549](/img/image-20211213065416549.png)

<img src="/img/image-20220503165944764.png" alt="image-20220503165944764" style="zoom:67%;" />

# HTTP篇

## HTTP 常见的状态码有哪些？

![image-20230317072056646](C:\Users\fuyunjinglong\AppData\Roaming\Typora\typora-user-images\image-20230317072056646.png)

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

## 一文读懂 HTTP/1、HTTP/2、HTTP/3

[《现代前端技术解析》笔记](https://www.cnblogs.com/happylittlefish/p/10470048.html)

HTTP 超文本传输协议是位于 TCP/IP 体系结构中的应用层协议。

<img src="/img/image-20220530071156663.png" alt="image-20220530071156663" style="zoom:80%;" />

**一、HTTP/1**

缺陷：

> 1. 高延迟 — 队头阻塞(Head-Of-Line Blocking)
> 2. 无状态特性 — 阻碍交互
> 3. 明文传输 — 不安全性
> 4. 不支持服务端推送

**队头阻塞**

队头阻塞是指当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据。

针对队头阻塞：

1.将同一页面的资源分散到不同域名下，提升连接上限。虽然能公用一个 TCP 管道，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。

2.减少请求数量

3.内联一些资源：css、base64 图片等

4.合并小文件减少资源数

**无状态特性**

无状态是指协议对于连接状态没有**记忆能力**。纯净的 HTTP 是没有 cookie 等机制的，每一个连接都是一个新的连接。上一次请求验证了用户名密码，而下一次请求服务器并不知道它与上一条请求有何关联，换句话说就是**掉登录态**。

**不安全性**

传输内容没有加密，中途可能被篡改和劫持。

**二、SPDY 协议**

SPDY 是由 google 推行的改进版本的 HTTP1.1 （那时候还没有 HTTP2）

特点：

> 1. 多路复用 — 解决队头阻塞
> 2. 头部压缩 — 解决巨大的 HTTP 头部
> 3. 请求优先级 — 先获取重要数据
> 4. 服务端推送 — 填补空缺
> 5. 提高安全性

**多路复用**

SPDY 允许在一个连接上无限制并发流。因为请求在一个通道上，TCP 效率更高（参考 [TCP 拥塞控制](https://link.juejin.cn?target=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F37379780) 中的**慢启动**）。更少的网络连接，发出更密集的包。

**头部压缩**

使用专门的 HPACK 算法，每次请求和响应只发送差异头部，一般可以达到 50% ~90% 的高压缩率。

**请求优先级**

虽然无限的并发流解决了队头阻塞的问题，但如果带宽受限，客户端可能会因防止堵塞通道而阻止请求。在网络通道被非关键资源堵塞时，高优先级的请求会被优先处理。

**服务端推送**

[服务端推送（ServerPush）](https://link.juejin.cn?target=http%3A%2F%2Fwww.ruanyifeng.com%2Fblog%2F2018%2F03%2Fhttp2_server_push.html)，可以让服务端主动把资源文件推送给客户端。当然客户端也有权利选择是否接收。

**提高安全性**

支持使用 HTTPS 进行加密传输。



**三、HTTP/2**

HTTP2 基于 SPDY，专注于性能，最大的一个目标是在用户和网站间只用一个连接。

特点：

> 1. 二进制分帧 - HTTP2 性能增强的核心
> 2. 多路复用 - 解决串行的文件传输和连接数过多

**二进制分帧**

首先，HTTP2 没有改变 HTTP1 的语义，只是在应用层使用二进制分帧方式传输。因此，也引入了新的通信单位：**帧、消息、流**。

分帧有什么好处？服务器单位时间接收到的请求数变多，可以提高并发数。最重要的是，为多路复用提供了底层支持。

**多路复用**

一个域名对应一个连接，一个流代表了一个完整的**请求-响应**过程。**帧**是最小的数据单位，每个**帧**会标识出该帧属于哪个**流**，**流**也就是多个帧组成的数据流。多路复用，就是在一个 TCP 连接中可以存在多个流。

缺点：

> 1. TCP 以及 TCP+TLS 建立连接的延时
> 2. TCP 的队头阻塞并没有彻底解决
> 3. 多路复用导致服务器压力上升
> 4. 多路复用容易 Timeout

**建连延时**

TCP 连接需要和服务器进行**三次握手**，即消耗完 1.5 个 RTT 之后才能进行数据传输。

TLS 连接有两个版本—— TLS1.2 和 TLS1.3，每个版本建立连接所花的时间不同，大致需要 1~2 个 RTT。

RTT（Round-Trip Time）:往返时延。表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。

**队头阻塞没有彻底解决**

TCP 为了保证可靠传输，有一个“超时重传”机制，丢失的包必须等待重传确认。HTTP2 出现丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。

![img](C:/Program%20Files/Typora)

RTO：英文全称是 Retransmission TimeOut，即重传超时时间；RTO 是一个动态值，会根据网络的改变而改变。RTO 是根据给定连接的往返时间 RTT 计算出来的。接收方返回的 ack 是希望收到的下一组包的序列号。

**多路复用导致服务器压力上升**

多路复用没有限制同时请求数。请求的平均数量与往常相同，但实际会有许多请求的短暂爆发，导致瞬时 QPS 暴增。

**多路复用容易 Timeout**

大批量的请求同时发送，由于 HTTP2 连接内存在多个并行的流，而网络带宽和服务器资源有限，每个流的资源会被稀释，虽然它们开始时间相差更短，但却都可能超时。

即使是使用 Nginx 这样的负载均衡器，想正确进行节流也可能很棘手。其次，就算你向应用程序引入或调整排队机制，但一次能处理的连接也是有限的。如果对请求进行排队，还要注意在响应超时后丢弃请求，以避免浪费不必要的资源。



**四、HTTP/3**

Google在推 SPDY 的时候就已经意识到了这些问题，于是就另起炉灶搞了一个基于 UDP 协议的 QUIC 协议。而这个就是 HTTP3。它真正“完美”地解决了“队头阻塞”问题。

特点：

> 1. 改进的拥塞控制、可靠传输
> 2. 快速握手
> 3. 集成了 TLS 1.3 加密
> 4. 多路复用
> 5. 连接迁移

**改进的拥塞控制、可靠传输**

从拥塞算法和可靠传输本身来看，QUIC 只是按照 TCP 协议重新实现了一遍，那么 QUIC 协议到底改进在哪些方面呢？主要有如下几点：

1. 可插拔 — 应用程序层面就能实现不同的拥塞控制算法。

一个应用程序的不同连接也能支持配置不同的拥塞控制。应用程序不需要停机和升级就能实现拥塞控制的变更，可以针对不同业务，不同网络制式，甚至不同的 RTT，使用不同的拥塞控制算法。

关于应用层的可插拔拥塞控制模拟，可以对 socket 上的流为对象进行实验。

2. 单调递增的 Packet Number — 使用 Packet Number 代替了 TCP 的 seq。

每个 Packet Number 都严格递增，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。而 TCP 重传策略存在二义性，比如客户端发送了一个请求，一个 RTO 后发起重传，而实际上服务器收到了第一次请求，并且响应已经在路上了，当客户端收到响应后，得出的 RTT 将会比真实 RTT 要小。当 Packet N 唯一之后，就可以计算出正确的 RTT。

3. 不允许 Reneging — 一个 Packet 只要被 Ack，就认为它一定被正确接收。

Reneging 的意思是，接收方有权把已经报给发送端 [SACK（Selective Acknowledgment）](https://link.juejin.cn?target=https%3A%2F%2Fallen-kevin.github.io%2F2017%2F03%2F01%2FTCP%E9%87%8D%E7%82%B9%E7%B3%BB%E5%88%97%E4%B9%8Bsack%E4%BB%8B%E7%BB%8D%2F) 里的数据给丢了（如接收窗口不够而丢弃乱序的包）。

QUIC 中的 ACK 包含了与 TCP 中 SACK 等价的信息，但 QUIC 不允许任何（包括被确认接受的）数据包被丢弃。这样不仅可以简化发送端与接收端的实现难度，还可以减少发送端的内存压力。

4. 前向纠错（FEC）

早期的 QUIC 版本存在一个丢包恢复机制，但后来由于增加带宽消耗和效果一般而**废弃**。FEC 中，QUIC 数据帧的数据混合原始数据和冗余数据，来确保无论到达接收端的 n 次传输内容是什么，接收端都能够恢复所有 n 个原始数据包。FEC 的实质就是异或。示意图：

![img](C:/Program%20Files/Typora)

5. 更多的 Ack 块和增加 Ack Delay 时间。

QUIC 可以同时提供 256 个 Ack Block，因此在重排序时，QUIC 相对于 TCP（使用 SACK）更有弹性，这也使得在**重排序**或**丢失**出现时，QUIC 可以在网络上保留更多的[在途字节](https://link.juejin.cn?target=https%3A%2F%2Fblog.csdn.net%2Fu014023993%2Farticle%2Fdetails%2F85299434)。在丢包率比较高的网络下，可以提升网络的恢复速度，减少重传量。

TCP 的 Timestamp 选项存在一个问题：发送方在发送报文时设置发送时间戳，接收方在确认该报文段时把时间戳字段值复制到确认报文时间戳，但是没有计算接收端接收到包到发送 Ack 的时间。这个时间可以简称为 Ack Delay，会导致 RTT 计算误差。现在就是把这个东西加进去计算 RTT 了。

6. 基于 stream 和 connection 级别的流量控制。

为什么需要两类流量控制呢？主要是因为 QUIC 支持多路复用。Stream 可以认为就是一条 HTTP 请求。Connection 可以类比一条 TCP 连接。多路复用意味着在一条 Connetion 上会同时存在多条 Stream。

QUIC 接收者会通告每个流中最多想要接收到的数据的绝对字节偏移。随着数据在特定流中的发送，接收和传送，接收者发送 WINDOW_UPDATE 帧，该帧增加该流的通告偏移量限制，允许对端在该流上发送更多的数据。

除了每个流的流控制外，QUIC 还实现连接级的流控制，以限制 QUIC 接收者愿意为连接分配的总缓冲区。连接的流控制工作方式与流的流控制一样，但传送的字节和最大的接收偏移是所有流的总和。

最重要的是，我们可以在内存不足或者上游处理性能出现问题时，通过流量控制来限制传输速率，保障服务可用性。

**快速握手**

由于 QUIC 是基于 UDP 的，所以 QUIC 可以实现 0-RTT 或者 1-RTT 来建立连接，可以大大提升首次打开页面的速度。

**集成了 TLS 1.3 加密**

TLS 1.3 支持 3 种基本密钥交换模式：

```scss
(EC)DHE (基于有限域或椭圆曲线的 Diffie-Hellman)
PSK - only
PSK with (EC)DHE
```

在完全握手情况下，需要 1-RTT 建立连接。TLS1.3 恢复会话可以直接发送加密后的应用数据，不需要额外的 TLS 握手，也就是 0-RTT。

但是 TLS1.3 也并不完美。TLS 1.3 的 0-RTT 无法保证前向安全性(Forward secrecy)。简单讲就是，如果当攻击者通过某种手段获取到了 Session Ticket Key，那么该攻击者可以解密以前的加密数据。

要缓解该问题可以通过设置使得与 Session Ticket Key 相关的 DH 静态参数在短时间内过期（一般几个小时）。

**多路复用**

QUIC 是为多路复用从头设计的，携带个别流的的数据的包丢失时，通常只影响该流。QUIC 连接上的多个 stream 之间并没有依赖，也不会有底层协议限制。假如 stream2 丢了一个包，也只会影响 stream2 的处理。

**连接迁移**

TCP 是按照 4 要素（客户端 IP、端口, 服务器 IP、端口）确定一个连接的。而 QUIC 则是让客户端生成一个 Connection ID （64 位）来区别不同连接。只要 Connection ID 不变，连接就不需要重新建立，即便是客户端的网络发生变化。由于迁移客户端继续使用相同的会话密钥来加密和解密数据包，QUIC 还提供了迁移客户端的自动加密验证。

**参考**

[一文读懂 HTTP/1、HTTP/2、HTTP/3](https://juejin.cn/post/7175344580638801975#heading-29)

## 彻底搞懂Https

**HTTPS本质**

<img src="/img/image-20220525071935357.png" alt="image-20220525071935357" style="zoom: 80%;" />

**HTTPS，其实就是身披SSL协议这层外壳的HTTP**

<img src="/img/image-20220525071136513.png" alt="image-20220525071136513" style="zoom:50%;" />

<img src="/img/image-20220525071155966.png" alt="image-20220525071155966" style="zoom: 50%;" />

HTTPS 协议的主要功能基本都依赖于 TLS/SSL 协议，TLS/SSL 的功能实现主要依赖于三类基本算法：

> 1. 非对称加密：**实现身份认证和密钥协商**
> 2. 对称加密：**采用协商的密钥对数据加密**
> 3. 散列函数 ：**基于散列函数验证信息的完整性**

**对称加密**

一句话：有一把秘钥，可以加密信息，也可以解密信息。

<img src="/img/image-20220525071649743.png" alt="image-20220525071649743" style="zoom:67%;" />

用对称加密可行？

> - 秘钥传输过程中，被人劫持了，就能用秘钥解开双方加密的内容
>
> - 秘钥不传输，事先浏览器保存所有网站的秘钥，就不存在秘钥劫持问题，但成本太高

**非对称加密**

一句话：有两把密钥，一把叫做公钥、一把叫私钥，公钥加密，私钥解密。

<img src="/img/image-20220525071734195.png" alt="image-20220525071734195" style="zoom:67%;" />

用非对称加密可行？

> - 服务器将公钥明文传输给客户端，如果公钥被劫持了，虽然保证客户端到服务端安全，但服务端到客户端不安全，服务端私钥加密的会被黑客劫持的公钥解密

**改良的非对称加密**

一句话：非对称加密只能保证单一方向的安全，那么我们用两对公钥秘钥。如服务器有公钥A私钥A,客户端有公钥B私钥B.

用改良的非对称加密可行？

> - 服务端将公钥A发给客户端，客户端将公钥B发给服务端，这样秘钥始终不被泄密，安全了，但非对称加密算法非常耗时，开销成本太大

**非对称+对称加密**

一句话：服务端有公钥A私钥A,服务端将公钥A明文发送给客户端，客户端用公钥A将随机生成的秘钥X加密传输给服务端，随后两端用对称秘钥X通信

Https采用的就是这种，但完美？

> - 仍有漏洞，在服务端发送公钥A时，黑客劫持并用冒充的公钥B替换了A,客户端用冒充的公钥B传输秘钥X,黑客又劫持并拿私钥B解密得到秘钥X。**根本原因是浏览器无法确认收到的公钥是不是网站自己的**

**数字证书**

网站在使用HTTPS前，需要向**CA机构**申领一份**数字证书**，数字证书里含有证书持有者信息、公钥信息等。证书相当于是一个网站的身份证。

数字证书安全？

> - 黑客容易伪造证书，也不安全

**数字签名**

一句话：用数字签名保证数字证书也是安全的

流程包括：服务端的数字签名+客户端的数字验证

数字签名

> 1. CA机构拥有非对称加密的私钥和公钥。
> 2. CA机构对证书明文数据T进行hash。
> 3. 对hash后的值用私钥加密，得到数字签名S。

数字验证

> 1. 拿到证书，得到明文T，签名S。
> 2. 用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到S’。
> 3. 用证书里指明的hash算法对明文T进行hash得到T’。
> 4. 显然通过以上步骤，T’应当等于S‘，除非明文或签名被篡改。所以此时比较S’是否等于T’，等于则表明证书可信。

其他问题

```
中间人有可能篡改该证书吗？
假设中间人篡改了证书的原文，由于他没有CA机构的私钥，所以无法得到此时加密后签名，无法相应地篡改签名。浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书已被篡改，证书不可信，从而终止向服务器传输信息，防止信息泄露给中间人。
既然不可能篡改，那整个证书被掉包呢？

中间人有可能把证书掉包吗？
假设有另一个网站B也拿到了CA机构认证的证书，它想劫持网站A的信息。于是它成为中间人拦截到了A传给浏览器的证书，然后替换成自己的证书，传给浏览器，之后浏览器就会错误地拿到B的证书里的公钥了，这确实会导致上文“中间人攻击”那里提到的漏洞？
其实这并不会发生，因为证书里包含了网站A的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了。

为什么制作数字签名时需要hash一次？
我初识HTTPS的时候就有这个疑问，因为似乎那里的hash有点多余，把hash过程去掉也能保证证书没有被篡改。
最显然的是性能问题，前面我们已经说了非对称加密效率较差，证书信息一般较长，比较耗时。而hash后得到的是固定长度的信息（比如用md5算法hash后可以得到固定的128位的值），这样加解密就快很多。
```

# TCP篇

## TCP是什么?

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

> - **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
> - **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
> - **字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文

## 什么是TCP连接

定义：**用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接。**

> - Socket：由 IP 地址和端口号组成
> - 序列号：用来解决乱序问题等
> - 窗口大小：用来做流量控制

##  如何唯一确定一个 TCP 连接呢？

##  **为什么是三次握手？不是两次、四次？**

## TCP和UDP

TCP特点：

- 是面向连接的通信协议，通过三次握手建立连接，通讯完成时要拆除连接。
- 只能用于端到端的通讯，是一种可靠的数据流服务
- 采用“带重传”技术来实现传输的可靠性。
- 采用“滑动窗口”的方式进行流量控制，所谓窗口实际表示接收能力，用以限制发送方的发送速度。

**使用TCP的协议：FTP（文件传输协议）、Telnet（远程登录协议）、SMTP（简单邮件传输协议）、POP3（和SMTP相对，用于接收邮件）、HTTP协议等。**

UDP特点：

- 面向无连接的通讯协议，可以实现广播发送
- 不需要接收方确认，属于不可靠的传输，可能会出现丢包现象
- 服务需要交换的信息量较小，速度快

**使用UDP协议包括：TFTP（简单文件传输协议）、SNMP（简单网络管理协议）、DNS（域名解析协议）、NFS、BOOTP。**

**TCP 与 UDP 的区别：TCP是面向连接的，可靠的字节流服务；UDP是面向无连接的，不可靠的数据报服务。**

# IP篇

# 跨域跨端

基于浏览器存在的同源策略，协议、域名、端口不一样。

目前主要使用JSONP和跨域资源共享CROS.

JSON本质就是一段script脚本，脚本是可以不受跨域限制的。只支持get请求，不符合正常业务流程

CROS是服务端设置Access-controll-Allow-Origin:*

# 网络缓存

[一文读懂http缓存（超详细）](https://www.jianshu.com/p/227cee9c8d15)

<img src="/img/image-20221022172938348.png" alt="image-20221022172938348" style="zoom: 67%;" />

**缓存术语**

> - 缓存命中率：从缓存中得到数据的请求数与所有请求数的比率
> - 过期内容：超过设置的有效时间。过期内容不能用于回复客户端的请求，必须重新向源服务器请求新内容
> - 验证：验证缓存中的过期内容是否仍然有效，验证通过的话刷新过期时间
> - 失效：失效就是把内容从缓存中移除。当内容发生改变时，必须移除失效的内容

按照缓存位置分类：

> - Service Worker 
> - memory cache
> - disk cache（也叫http缓存）

按照类别分类：

> - 浏览器缓存
>   - 本地缓存
>     - Cookie
>     - WebStoreage(SessionStorage,LocalStorage)
>     - WebSql
>     - indexDB
>     - Application Cache
>     - PWA
>   - 默认缓存—往返缓存BFCache
> - http缓存
>   - 强缓存
>     - Pragma
>     - Cache-Control
>     - Expires
>   - 协商缓存
>     - ETag/If-None-Match
>     - Last-Modified/If-Modified-Since

# 网络缓存-浏览器缓存

**分为两大类:**

> - 本地缓存
>   - Cookie
>   - WebStoreage(SessionStorage,LocalStorage)
>   - WebSql/indexDB
>   - Application Cache
>   - 应用缓存(manifest,PWA即Servie Worker)
> - 默认缓存—往返缓存BFCache

## Cookies、SessionStorage和LocalStorage

**定义**

> - cookie 是网站为了标示用户身份而储存在用户本地终端上的数据。cookie 数据始终在同源的http请求中携带，也会在浏览器和服务器间来回传递。
> - sessionStorage 和 localStorage 不会自动把数据发给服务器，仅在本地保存。

**存储大小**

> - cookie 数据大小不能超过 4k。
> - sessionStorage 和 localStorage可以达到 5M 或更大。

**有期时间**

> - cookie 设置的 cookie 过期时间之前一直有效，即使窗口或浏览器关闭。默认是关闭浏览器后失效。
> - sessionStorage 数据在当前浏览器窗口关闭后自动删除。
> - localStorage 存储持久数据，浏览器关闭后数据不丢失除非主动删除数据；

## Cookie

**Cookie机制**

> `Cookie`是解决HTTP无状态性的有效手段，服务器可以设置或读取`Cookie`中所包含的信息。
>
> 当用户登录后，服务器会发送包含登录凭据的`Cookie`到用户浏览器客户端，而浏览器对该`Cookie`进行某种形式的存储（内存或硬盘）。
>
> 用户再次访问该网站时，浏览器会发送该`Cookie`（Cookie未到期时）到服务器，服务器对该凭据进行验证，合法时使用户不必输入用户名和密码就可以直接登录。

**Cookie工作过程**

> 1. 客户端发送一个请求给服务器
> 2. 服务器发送一个`HttpResponse响应`给客户端，其中包含`Set-Cookie`的头部
> 3. 客户端保存cookie，之后向服务器发送请求时，HttpRequest请求中会包含一个Cookie的头部
> 4. 服务器返回响应数据

## Session

**Session机制**

Session的工作机制离不开Cookie：在cookie中有一个键名为sessionId，值为Session的id。对于不支持cookie的手机端，可以采用URL重写携带sessionId。

> 当客户端请求创建一个session时，服务端会先检查客户端的请求里面有没有带着session标识-sessionId。
>
> 如果有，则说明服务器以前已为此客户端创建过session，于是就根据这个sessionId把session检索出来。
>
> 如果客户端请求中不包含sessionId，则为客户端创建一个session并且生成一个与这个session相关联的sessionId。 这个sessionId将被在本次响应中返回给客户端保存。

**WebStoreage**

包括：sessionStorage 和 localStorage

> - sessionStorage 和 localStorage 不会自动把数据发给服务器，仅在本地保存。
> - sessionStorage 和 localStorage可以达到 5M 或更大。
> - sessionStorage 数据在当前浏览器窗口关闭后自动删除。
> - localStorage 存储持久数据，浏览器关闭后数据不丢失除非主动删除数据；

**WebSql/indexDB**

前端数据库有WebSql和IndexDB，其中WebSql被规范废弃，他们都有大约50MB的最大容量，可以理解为localStorage的加强版。

## Application Cache

## 应用缓存-manifest即HTML5的离线缓存

通过manifest文件来注册被缓存的静态资源，已经被废弃，因为他的设计有些不合理的地方，他在缓存静态文件的同时，也会默认缓存html文件。这导致页面的更新只能通过manifest文件中的版本号来决定。所以，应用缓存只适合那种常年不变化的静态网站。如此的不方便，也是被废弃的重要原因。

**定义**

在用户没有与因特网连接时，可以正常访问站点或应用

**原理**

HTML5离线缓存是基于manifest(缓存清单文件，后缀名为.appcache)的缓存机制，通过这个文件上的清单解析存储离线资源，就像cookie一样被存在本地，之后当处于离线状态时，就直接使用离线存储的资源进行页面的展示。

好处：

- 离线浏览，不再需要网络
- 速度快，已缓存的资源加载更快
- 减轻服务器压力，用户无需网络请求缓存资源

**使用**

1. h5头部标签引入manifest属性，值为manifest清单文件
2. 在manifest清单文件中编写离线存储的资源
3. 操作window.applicationCache进行缓存数据处理

manifest清单文件：

```
CACHE MANIFEST
#v0.11
CACHE: // 需要缓存的
js/app.js
css/style.css
NETWORK: // 不缓存的
resourse/logo.png
FALLBACK: // 网络失败时的替换页面
//offline.html
```

window.applicationCache.status的属性值如下：

- 0：（UNCACHED）无缓，代表没有与当前页面相关的缓存资源；
- 1：（IDLE）闲置，代表应用缓存未得到更新；
- 2：（CHECKING）检查中，正在下载描述文件，并检查有无更新；
- 3：（DOWNLOADING）下载中，应用缓存正在下载描述文件中的资源；
- 4：（UPDATEREADY）更新完成，所有资源下载完毕；
- 5：（）废弃，即应用缓存的描述文件不存在了，因此页面无法在访问应用缓存；

**更新缓存时机**

1. 用户清空浏览器缓存；
2. manifest文件被修改；
3. 由程序来更新应用缓存；

**h5缓存与浏览器缓存区别**

- 离线缓存是针对整个应用，但是浏览器缓存是针对单个文件；
- 离线缓存断网了还可以继续访问，浏览器缓存不行；
- 离线缓存可以主动通知浏览器更新；

## 应用缓存-PWA即Servie Worker

PWA全称是渐进式网络应用，PWA也运用了manifest文件，不同于manifest简单的将文件通过是否缓存进行分类，PWA用manifest构建了自己的APP骨架，并运用Servie Worker来控制缓存。

PWA即Progressive Web Apps。谷歌给以Service Worker API为核心的实现web应用取名PWA即渐进式增强WEB应用。有点类似移动端小程序一样，在web上运行，不需要独立安装的web微应用。

**PWA**

PWA全称Progressive Web Apps（渐进式WebApp），是通过现代API来构建和增强的，这些API提供了与原生App相似的能力、可靠性、可安装性，而且具备一套代码即可触达任何人、任何地方、任何设备。PWA同时具备这三大特性，这也让PWA的应用体验更接近原生。

三大特性：

- 功能性（capable）
- 可靠性（reliable）
- 可安装性（installable）

功能性

Web App当今时代已经具备了丰富的功能，你可以基于 `WebRTC` 开发一个视频聊天工具，可以使用 `Geolocation API` 开发一个地图软件，也可以使用 `Notification API` 来给你的APP推送消息，让用户可以在APP之外接收到通知。你也可以使用 `WebGL` 和 `WebVR` 来虚拟化这些场景。通过 `Web Assembly`，你可以步入其他生态，比如：C和C++等，给Web生态带来更多能力。

可靠性

可靠的App需要对网络无依赖。用户会期望在弱网或者无网络的情况下打开App。他们期望看到上次他们加载的内容，就像是音频或者视频播放到某个特定时间点，即使网络连接困难，还是要保持可靠和可用。如果请求失败了，比起默默地失败或者崩溃，给用户合理的提示才是最佳。

可安装性

安装好的PWA应用可以在一个独立的窗口启动，而不用在浏览器中。它们也可以从主页、docks或者任务栏启动。

小结

PWA的核心还是WebApp，通过渐进式增强，新的功能被现代浏览器实现。通过使用 `service worker` 和 `app manifest`，可以让你的WebApp具备可靠性和可安装性。如果浏览器不支持这些功能，你的网站的核心功能也不受影响。

如果说一个30M的原生App换成PWA，可能只有3M不到。另外，PWA的应用的可触达性是继承了WebApp的，可以通过搜索引擎让触达更多用户，或者通过分享的方式。最后，PWA的应用可随时更新，无需用户下载安装。

**Service Worker**

什么是Service Worker

Service Worker是一项比较新的Web技术，是Chromium团队在吸收了ChromePackaged App的Event Page机制，同时吸取了HTML5 AppCache标准失败的教训之后，提出一套新的W3C规范，旨在提高WebApp的离线缓存能力，缩小WebApp与NativeApp之间差距。

Service Worker从英文翻译过来就是一个服务工人，服务于前端页面的后台线程，基于Web Worker实现。有着独立的js运行环境，分担、协助前端页面完成前端开发者分配的需要在后台悄悄执行的任务。基于它可以实现拦截和处理网络请求、消息推送、静默更新、事件同步等服务。

应用场景

1、离线缓存：可以将H5应用中不变化的资源或者很少变化的资源长久的存储在用户端，提升加载速度、降低流量消耗、降低服务器压力。如中重度的H5游戏、框架数据独立的web资讯客户端、web邮件客户端等

2、消息推送：激活沉睡的用户，推送即时消息、公告通知，激发更新等。如web资讯客户端、web即时通讯工具、h5游戏等运营产品。

3、事件同步：确保web端产生的任务即使在用户关闭了web页面也可以顺利完成。如web邮件客户端、web即时通讯工具等。

4、定时同步：周期性的触发Service Worker脚本中的定时同步事件，可借助它提前刷新缓存内容。如web资讯客户端。

## **往返缓存-BFCache**

往返缓存又称为BFCache，是浏览器在前进后退按钮上为了提升历史页面的渲染速度的一种策略。BFCache会缓存所有的DOM结构，但是问题在于，一些页面开始时进行的上报或者请求可能会被影响。这个问题现在主要会出现在微信h5的开发中。

# 网络缓存-http缓存

**分为两大类：**

> - 强缓存
>   - Pragma
>   - Cache-Control
>   - Expires
> - 协商缓存
>   - ETag/If-None-Match
>   - Last-Modified/If-Modified-Since

分为强缓存和协商缓存，浏览器加载一个页面的简单流程如下：

1. 浏览器先根据这个资源的http头信息来判断是否命中强缓存，如果命中则直接加在缓存中的资源，并不会将请求发送到服务器
2. 如果未命中强缓存，则浏览器会将资源加载请求发送到服务器。服务器来判断浏览器本地缓存是否失效。若可以使用，则服务器并不会返回资源信息，浏览器继续从缓存加载资源
3. 如果未命中协商缓存，则服务器会将完整的资源返回给浏览器，浏览器加载新资源，并更新缓存

**缓存策略：**

- 不常变化的资源，Cache-Control: max-age=31536000；
- 经常变化的资源，Cache-Control: no-cache
- 比较敏感的资源，Cache-Control: max-age=600

![image-20211111182141513](/img/image-20211111182141513.png)

强缓存

- 不存在该缓存结果和标识，强制缓存失效，则直接向服务器发起请求（跟第一次发起请求一致）
- 存在缓存结果和标识，但结果已失效，强制缓存失效，则使用协商缓存
- 存在缓存结果和标识，并且结果未失效，强制缓存生效，直接返回该结果

协商缓存

- 协商缓存生效，返回304，服务器告诉浏览器资源未更新，则再去浏览器缓存中访问资 源
- 协商缓存失效，返回200和请求结果

**强制缓存：不需要发送请求到服务器**

若命中强缓存，浏览器并不会将请求发送给服务器。http返回码是200，后缀为(from cache或from memory cache)。强缓存是利用http的返回头中的Expires或Cache-Control两个字段来控制的，用来表示资源的缓存时间。

- Expires：Thu ,25,Apr 2019 12:25:36 GTM，是绝对时间


- Cache-Control:max-age=0, private, must-revalidate，是相对时间段,优先级更高

Expires是HTTP1.0的产物了，现在默认浏览器均默认使用HTTP 1.1，所以它的作用基本忽略。但是很多网站还是对它做了兼容。它的值为服务端返回的到期时间，即下一次请求时，请求时间小于服务端返回的到期时间，直接使用缓存数据。
在HTTP 1.1 的版本，使用Cache-Control取值有private、public、no-cache、max-age，no-store，默认为private。

> - max-age：用来设置资源（representations）可以被缓存多长时间，单位为秒；
> - s-maxage：和max-age是一样的，不过它只针对代理服务器缓存而言；
>   public：指示响应可被任何缓存区缓存；
> - private：只能针对个人用户，而不能被代理服务器缓存；
> - no-cache：强制客户端直接向服务器发送请求,也就是说每次请求都必须向服务器发送。服务器接收到请求，然后判断资源是否变更，是则返回新内容，否则返回304，未变更。这个很容易让人产生误解，使人误 以为是响应不被缓存。实际上Cache-Control: no-cache是会被缓存的，只不过每次在向客户端（浏览器）提供响应数据时，缓存都要向服务器评估缓存响应的有效性。
> - no-store：禁止一切缓存（这个才是响应不被缓存的意思）。

**协商缓存：需要发送请求到服务器**

若未命中强缓存，则浏览器会将请求发送到服务器。服务器根据http请求头信息中Last-modify/If-modify-Since或Etag/If-None-Match来判断是否命中协商缓存。如果命中，则http返回码为304，浏览器从缓存加载资源。协商主要是问服务器，我访问的文件有没有更新。

- Last-modify/If-modify-Since: "2022-02-25 15:30.3"，表示文件修改的时间
- Etag/If-None-Match: W/"e39f603a5ebcff23859d200f9c9dc20f"，表示每个资源的是否修改的文件校验码。

Last-Modified/If-Modified-Since，第一次请求，服务端返回Last-modify。第二次请求，请求头携带If-modify-Since，如果服务器判断Last-modify和If-modify-Since时间相同，则命中协商缓存。

Etag/If-None-Match，第一次请求，服务端返回Etag。第二次请求，请求头携带If-None-Match，如果服务器判断Etag和If-None-Match相同，则命中协商缓存。

Etag 等字段是指文件是否发生变化。Last-Modified 表示最近1s时间，文件的请求时间。后者对于1s内变化的数据，无法感知，会误以为没变化，取缓存数据。

**nginx配置缓存策略**

> nginx配置Cache-Control: no-cache。不使用强缓存。
>
> **304 Not modified表示协商缓存**，

<img src="/img/image-20221023110951987.png" alt="image-20221023110951987" style="zoom:80%;" />

> nginx配置Cache-Control: max-age=60。60S内命中强缓存，60s后使用协商缓存。
>
> **200ok(from memory cache)表示强缓存**
>
> 强缓存好处：不用请求到服务器，缓解高并发访问压力。

<img src="/img/image-20221023111935322.png" alt="image-20221023111935322" style="zoom:80%;" />

**用户动作**

```
用户打开页面，不会强制干涉内存策略，执行强缓存。流程：命中则返回200取缓存，否则执行协商缓存。
F5刷新，跳过强缓存，执行协商缓存，原理：cache-control:max-age=0,且设置If-Modified-Since给服务端比对。流程：命中则返回304取缓存，否则返回200取服务端数据。
ctrl+F5，跳过强缓存和协商缓存，原理：cache-control:no-cache,且不设置If-Modified-Since。
```

*max-age=0和no-cache区别*

如果用户代理使用 Cache-Control: max-age=0（又名“端到端重新验证”）发送请求，那么沿途的每个缓存都将重新验证其缓存条目.

如果使用 Cache-Control: no-cache（又名“端到端重新加载”）发送请求不会重新验证，并且服务器在响应时不得使用缓存副本。

# 常见六大Web安全攻防解析

## XSS

XSS (Cross-Site Scripting)，跨站脚本攻击，因为缩写和 CSS重叠，所以只能叫 XSS。

跨站脚本攻击是指通过存在安全漏洞的Web网站注册用户的浏览器内运行非法的HTML标签或JavaScript进行的一种攻击。

按照攻击方式分：

- 非持久型跨站（也叫反射型）
- 持久型跨站（也叫存储型）
- DOM跨站

**一、反射型**

一般是通过给别人发送**带有恶意脚本代码参数的 URL**，当 URL 地址被打开时，特有的恶意代码参数被 HTML 解析、执行。

特点：

> - 即时性，不经过服务器存储，直接通过 HTTP 的 GET 和 POST 请求就能完成一次攻击，拿到用户隐私数据。
> - 攻击者需要诱骗点击,必须要通过用户点击链接才能发起
> - 反馈率低，所以较难发现和响应修复
> - 盗取用户敏感保密信息

反制：

> - Web 页面渲染的所有内容或者渲染的数据都必须来自于服务端。
>
> - 尽量不要从 `URL`，`document.referrer`，`document.forms` 等这种 DOM API 中获取数据直接渲染。
>
> - 尽量不要使用 `eval`, `new Function()`，`document.write()`，`document.writeln()`，`window.setInterval()`，`window.setTimeout()`，`innerHTML`，`document.createElement()` 等可执行字符串的方法。
>
> - 如果做不到以上几点，也必须对涉及 DOM 渲染的方法传入的字符串参数做 escape 转义。
>
> - 前端渲染的时候对任何的字段都需要做 escape 转义编码。

**二、存储型**

黑客利用的 XSS 漏洞，将内容经正常功能提交进入数据库持久保存，当前端页面获得后端从数据库中读出的注入代码时，恰好将其渲染执行。

特点：

> - 持久性，植入在数据库中
> - 盗取用户敏感私密信息
> - 危害面广

反制：

> - CSP即白名单
> - 转义字符
> - HttpOnly Cookie

 **CSP**

CSP 本质上就是建立白名单，开发者明确告诉浏览器哪些外部资源可以加载和执行。我们只需要配置规则，如何拦截是由浏览器自己实现的。我们可以通过这种方式来尽量减少 XSS 攻击。

通常可以通过两种方式来开启 CSP：

- 设置 HTTP Header 中的 Content-Security-Policy
- 设置 meta 标签的方式 

这里以设置 HTTP Header 来举例：

- 只允许加载本站资源

```arduino
Content-Security-Policy: default-src 'self'
复制代码
```

- 只允许加载 HTTPS 协议图片

```less
Content-Security-Policy: img-src https://*
复制代码
```

- 允许加载任何来源框架

```css
Content-Security-Policy: child-src 'none'
复制代码
```

如需了解更多属性，请查看[Content-Security-Policy文档](https://link.juejin.cn?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FHTTP%2FHeaders%2FContent-Security-Policy)

**HttpOnly Cookie。**

这是预防XSS攻击窃取用户cookie最有效的防御手段。Web应用程序在设置cookie时，将其属性设为HttpOnly，就可以避免该网页的cookie被客户端恶意JavaScript窃取，保护用户cookie信息。

**三、DOM跨站**

- 攻击者构造出特殊的 `URL` ，其中包含恶意代码。
- 用户打开带有恶意代码的 `URL` 。
- 用户浏览器接收到响应后解析执行，前端 `JavaScript` 取出 `URL` 中的恶意代码并执行。
- 恶意代码窃取用户数据并发送到攻击者的网站，或者冒充用户的行为，调用目标网站接口执行攻击者指定的操作。

DOM 型跟前两种区别是：

DOM 型 XSS 攻击中，取出和执行恶意代码由**浏览器端**完成，属于前端 JavaScript 自身的安全漏洞，而其他两种 XSS 都属于**服务端**的安全漏洞。

## CSRF

CSRF(Cross Site Request Forgery)，即跨站请求伪造，是一种常见的Web攻击，它利用用户已登录的身份，在用户毫不知情的情况下，以用户的名义完成非法操作。

**攻击流程**：

> 1. 受害者登录 `a.com`，并保留了登录凭证（`Cookie`）。
> 2. 攻击者引诱受害者访问了 `b.com`。
> 3. `b.com` 向 `a.com` 发送了一个请求：`a.com/act=xx`。浏览器会**默认携带** `a.com` 的 `Cookie`。
> 4. `a.com` 接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求。
> 5. `a.com` 以受害者的名义执行了 `act=xx`。
> 6. 攻击完成，攻击者在受害者不知情的情况下，冒充受害者，让 `a.com` 执行了自己定义的操作。

反制：

> - Get 请求不对数据进行修改
> - 不让第三方网站访问到用户 Cookie
> - 阻止第三方网站请求接口
> - 请求时附带验证信息，比如验证码或者 Token

具体反制：

> 1) SameSite
>
> 可以对 Cookie 设置 SameSite 属性。该属性表示 Cookie 不随着跨域请求发送，可以很大程度减少 CSRF 的攻击，但是该属性目前并不是所有浏览器都兼容。
>
> 2) Referer Check同源检测
>
> referer 和 origin 的区别，只有 post 请求会携带 origin 请求头，而 referer不论何种情况下都带。
>
> HTTP Referer是header的一部分，当浏览器向web服务器发送请求时，一般会带上Referer信息告诉服务器是从哪个页面链接过来的，服务器籍此可以获得一些信息用于处理。可以通过检查请求的来源来防御CSRF攻击。正常请求的referer具有一定规律，如在提交表单的referer必定是在该页面发起的请求。所以**通过检查http包头referer的值是不是这个页面，来判断是不是CSRF攻击**。
>
> 但在某些情况下如从https跳转到http，浏览器处于安全考虑，不会发送referer，服务器就无法进行check了。若与该网站同域的其他网站有XSS漏洞，那么攻击者可以在其他网站注入恶意脚本，受害者进入了此类同域的网址，也会遭受攻击。出于以上原因，无法完全依赖Referer Check作为防御CSRF的主要手段。但是可以通过Referer Check来监控CSRF攻击的发生。
>
> 3)  Anti CSRF Token
>
> 目前比较完善的解决方案是加入Anti-CSRF-Token。即发送请求时在HTTP 请求中以参数的形式加入一个随机产生的token，并在服务器建立一个拦截器来验证这个token。服务器读取浏览器当前域cookie中这个token值，会进行校验该请求当中的token和cookie当中的token值是否都存在且相等，才认为这是合法的请求。否则认为这次请求是违法的，拒绝该次服务。
>
> **这种方法相比Referer检查要安全很多**，token可以在用户登陆后产生并放于session或cookie中，然后在每次请求时服务器把token从session或cookie中拿出，与本次请求中的token 进行比对。由于token的存在，攻击者无法再构造出一个完整的URL实施CSRF攻击。但在处理多个页面共存问题时，当某个页面消耗掉token后，其他页面的表单保存的还是被消耗掉的那个token，其他页面的表单提交时会出现token错误。
>
> 4) 验证码
>
> 应用程序和用户进行交互过程中，特别是账户交易这种核心步骤，强制用户输入验证码，才能完成最终请求。在通常情况下，验证码够很好地遏制CSRF攻击。**但增加验证码降低了用户的体验，网站不能给所有的操作都加上验证码**。所以只能将验证码作为一种辅助手段，在关键业务点设置验证码。

**cookie和token**

> **cookie 是不能跨域访问的，为什么还会有 csrf？**
>
> 浏览器会依据加载的域名附带上对应域名 cookie。如用户在 a 网站登录且生成了授权的 cookies，然后访问 b 网站，b 站故意构造请求 a 站的请求，如删除操作之类的，用不受同源影响的 script，img 或者 iframe 之类的标签加载 a 地址，浏览器会附带上 a 站此登录用户的授权 cookie 信息，这样就构成 crsf，会删除掉当前用户的数据。cookie和session都会有csrf问题，localstorge没有这个问题，因为它有同源策略。
>
> Token
>
> **示例：** 用户登录输入账号密码，请求登录接口，后端在用户登录信息正确的情况下将 `token` 放到**数据库**中，并返回 `token` 给前端，前端把 `token` 存放在 `localstorage` 中，之后再发送请求都会将 `token` 放到 `header` 中。 后端写一个过滤器，拦截 `POST` 请求，注意忽略掉不需要 `token` 的请求，比如登录接口，获取 `token` 的接口，以免还没有获取 `token` 就开始检验 `token` 。 校验原则：**数据库**中的 `token` 和前端 `header` 中的 `token` 一致的 `post` 请求，则说明校验成功，给客户端放行。

## 点击劫持

点击劫持是一种视觉欺骗的攻击手段。攻击者将需要攻击的网站通过 iframe 嵌套的方式嵌入自己的网页中，并将 iframe 设置为透明，在页面中透出一个按钮诱导用户点击。

特点：

> - 隐蔽性较高，骗取用户操作
> - "UI-覆盖攻击"
> - 利用iframe或者其它标签的属性

具体反制：

> 1）X-FRAME-OPTIONS
>
> `X-FRAME-OPTIONS`是一个 HTTP 响应头，在现代浏览器有一个很好的支持。这个 HTTP 响应头 就是为了防御用 iframe 嵌套的点击劫持攻击。
>
> 该响应头有三个值可选，分别是
>
> - DENY，表示页面不允许通过 iframe 的方式展示
> - SAMEORIGIN，表示页面可以在相同域名下通过 iframe 的方式展示
> - ALLOW-FROM，表示页面可以在指定来源的 iframe 中展示
>
> 2）JavaScript 防御
>
> ```
> if (self == top) {...}
> ```

## SQL注入

**SQL注入的本质:数据和代码未分离，即数据当做了代码来执行。**

反制：

> - **严格限制Web应用的数据库的操作权限**，给此用户提供仅仅能够满足其工作的最低权限，从而最大限度的减少注入攻击对数据库的危害
>
> - **后端代码检查输入的数据是否符合预期**，严格限制变量的类型，例如使用正则表达式进行一些匹配处理。
>
> - **对进入数据库的特殊字符（'，"，\，<，>，&，\*，; 等）进行转义处理，或编码转换**。基本上所有的后端语言都有对字符串进行转义处理的方法，比如 lodash 的 lodash._escapehtmlchar 库。
>
> - **所有的查询语句建议使用数据库提供的参数化查询接口**，参数化的语句使用参数而不是将用户输入变量嵌入到 SQL 语句中，即不要直接拼接 SQL 语句。例如 Node.js 中的 mysqljs 库的 query 方法中的 ? 占位参数

**参考**

- [常见六大Web安全攻防解析](https://juejin.im/post/5c446eb1e51d45517624f7db)

# CSR和SSR渲染方案

SEO（英文 Search Engine Optimization）字面理解很简单的，就是“搜索引擎优化”，最简单的理解就是“搜索自然排名”。seo实际上是做关键词排名优化，即对某个产品的某个关键词进行优化。 

SSR(Server Side Rendering) ：传统的渲染方式，由服务端把渲染的完整的页面吐给客户端。这样减少了一次客户端到服务端的一次http请求，加快相应速度，一般用于首屏的性能优化。

CSR(Client Side Rendering)：是一种目前流行的渲染方式，它依赖的是运行在客户端的JS，用户首次发送请求只能得到小部分的指引性HTML代码。第二次请求将会请求更多包含HTML字符串的JS文件。

**简而言之，SSR强在首屏渲染。而CSR强在用户和页面多交互的场景。**

![image-20211024185626382](/img/image-20211024185626382.png)

# WebSocket和Socket原理

**一、概述**

websocket是HTML5的一种新协议，允许服务器向客户端传递信息，实现浏览器和客户端双工通信。用来弥补http协议在持久通信能力上的不足。

http请求完传输数据后就结束了（虽然http1.1增加了keep-alive请求头可以通过一条通道请求多次，但本质上还是一样的），并且服务器是不能主动给客户端发送数据。

于2011年，WebSocket协议由此而生，webSocket 是基于HTTP协议的，或者说 *借用* HTTP的协议来完成一部分握手。

协议标识符是`ws`（如果加密，则为`wss`），服务器网址就是 URL

**可以把WebSocket想象成HTTP(应用层)，HTTP和Socket什么关系，WebSocket和Socket就是什么关系。**

<img src="/img/image-20220527070123156.png" alt="image-20220527070123156" style="zoom: 67%;" />

**二、原理**

websocket的连接建立过程:
1、客户端发送GET 请求， Connection: Upgrade和Upgrade: websocket。
2、服务器给客户端 switching protocol
3、就进行了webSocket的通信了

> 1. 如何建立连接
> 2. 如何交换数据
> 3. 数据帧格式
> 4. 如何维持连接

**1.如何建立连接**

**客户端：申请协议升级**

首先，客户端发起协议升级请求。可以看到，采用的是标准的HTTP报文格式，且只支持`GET`方法。

重点请求首部意义如下：

- `Connection: Upgrade`：表示要升级协议
- `Upgrade: websocket`：表示要升级到websocket协议。
- `Sec-WebSocket-Version: 13`：表示websocket的版本。如果服务端不支持该版本，需要返回一个`Sec-WebSocket-Version`header，里面包含服务端支持的版本号。
- `Sec-WebSocket-Key`：与后面服务端响应首部的`Sec-WebSocket-Accept`是配套的，提供基本的防护，比如恶意的连接，或者无意的连接。

**服务端：响应协议升级**

服务端返回内容如下，状态代码`101`表示协议切换。到此完成协议升级，后续的数据交互都按照新的协议来。

**Sec-WebSocket-Accept的计算**

`Sec-WebSocket-Accept`根据客户端请求首部的`Sec-WebSocket-Key`计算出来。

计算公式为：

1. 将`Sec-WebSocket-Key`跟`258EAFA5-E914-47DA-95CA-C5AB0DC85B11`拼接。
2. 通过SHA1计算出摘要，并转成base64字符串。

**2.数据帧格式**

WebSocket客户端、服务端通信的最小单位是帧（frame），由1个或多个帧组成一条完整的消息（message）。

1. 发送端：将消息切割成多个帧，并发送给服务端；
2. 接收端：接收消息帧，并将关联的帧重新组装成完整的消息；

WebSocket数据帧的统一格式。熟悉TCP/IP协议的同学对这样的图应该不陌生:

1. 从左到右，单位是比特。比如`FIN`、`RSV1`各占据1比特，`opcode`占据4比特。
2. 内容包括了标识、操作代码、掩码、数据、数据长度等。（下一小节会展开）

<img src="/img/image-20220527070714271.png" alt="image-20220527070714271" style="zoom: 80%;" />

**3.数据传递**

一旦WebSocket客户端、服务端建立连接后，后续的操作都是基于数据帧的传递。

WebSocket根据`opcode`来区分操作的类型。比如`0x8`表示断开连接，`0x0`-`0x2`表示数据交互。

**数据分片**

WebSocket的每条消息可能被切分成多个数据帧。当WebSocket的接收方收到一个数据帧时，会根据`FIN`的值来判断，是否已经收到消息的最后一个数据帧。

FIN=1表示当前数据帧为消息的最后一个数据帧，此时接收方已经收到完整的消息，可以对消息进行处理。FIN=0，则接收方还需要继续监听接收其余的数据帧。

此外，`opcode`在数据交换的场景下，表示的是数据的类型。`0x01`表示文本，`0x02`表示二进制。而`0x00`比较特殊，表示延续帧（continuation frame），顾名思义，就是完整消息对应的数据帧还没接收完。

**数据分片例子**

直接看例子更形象些。下面例子来自[MDN](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_servers)，可以很好地演示数据的分片。客户端向服务端两次发送消息，服务端收到消息后回应客户端，这里主要看客户端往服务端发送的消息。

**4.连接保持+心跳**

WebSocket为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的TCP通道保持连接没有断开。然而，对于长时间没有数据往来的连接，如果依旧长时间保持着，可能会浪费包括的连接资源。

但不排除有些场景，客户端、服务端虽然长时间没有数据往来，但仍需要保持连接。这个时候，可以采用心跳来实现。

- 发送方->接收方：ping
- 接收方->发送方：pong

ping、pong的操作，对应的是WebSocket的两个控制帧，`opcode`分别是`0x9`、`0xA`。

举例，WebSocket服务端向客户端发送ping，只需要如下代码（采用`ws`模块）

```js
ws.ping('', false, true);
```

**三、优缺点**

简单说：**在浏览器里使用；支持双向通信；使用简单**

优点：

- 支持双向通信，实时性更强。
- 更好的二进制支持。
- 较少的控制开销。连接创建后，ws客户端、服务端进行数据交换时，协议控制的数据包头部较小。在不包含头部的情况下，服务端到客户端的包头只有2~10字节（取决于数据包长度），客户端到服务端的的话，需要加上额外的4字节的掩码。而HTTP协议每次通信都需要携带完整的头部。
- 支持扩展。ws协议定义了扩展，用户可以扩展协议，或者实现自定义的子协议。（比如支持自定义压缩算法等）

缺点：

- 少部分浏览器不支持，浏览器支持的程度与方式有区别

**常用注解**

onConnection服务端监听连接

- onMessage服务端监听消息
- send服务端发送消息

onopen客户端打开连接

- send客户端发送消息

onMessage客户端监听消息

**四.基于NodeJs的实现websocket通信**

服务端

```
// 安装ws模块// npm install ws// 新建index.js文件// -----
// 导入ws模块const WebSocket = require('ws')
// 新建一个WebSocketServerconst wss = new WebSocket.Server({ port: 3000 })
// 服务器监听连接事件
wss.on('connection', ws => {

// 服务器监听消息事件 
 ws.on('message', msg => {
console.log('服务器收到：', msg)
 })

// 服务器向客户端发送消息
 ws.send('这是服务器发送的信息')
})
```

客户端

```
<!DOCTYPE html><html lang="en"><head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Document</title></head><body><script>
// 这是浏览器原生支持的WebSocket API，在支持HTML5标准的浏览器上可以直接使用
var ws = new WebSocket('ws://localhost:3000')

// 当连接成功后就可以发送消息了
 ws.onopen = function() {
console.log('连接已建立')
   ws.send('这是客户端发出的信息')
 }
// 收到消息后做对应的处理
 ws.onmessage = function(e) {
console.log(e.data)
 }</script></body></html>
```

**五、.socket、http和websocket的区别**

**http和websocket的区别:**

http协议是短链接，因为请求之后，都会关闭连接，下次请求需要重新打开链接。
websocket协议是一种长连接，只需要通过一次请求来初始化连接，然后所有请求和响应都是通过TCP链接进行通信。

**websocket和socket的区别:**

socket是应用层与TCP/IP协议通信的中间软件抽象层，它是一组接口api。而websocket协议是一个完整的应用层协议，拥有一套完整的API。

**socket的工作流程**

![image-20211225204424939](/img/image-20211225204424939.png)

1. 服务端初始化socket;
2. 服务端绑定端口bind;
3. 服务端监听端口listen,这是一个死循环;
4. 服务端阻塞，等待客户端来连接，accept;
5. 客户端初始化socket;
6. 客户端连接服务端，connect;
7. 客户端进行正常的read、write读写；
8. 最后双方关闭连接close；

**服务端实时通信的方案**

1、AJAX轮询
2、Long Polling长轮询
3、WebSocket

**Sec-WebSocket-Key/Accept的作用**

`Sec-WebSocket-Key/Sec-WebSocket-Accept`在主要作用在于提供基础的防护，减少恶意连接、意外连接。

作用大致归纳如下：

1. 避免服务端收到非法的websocket连接（比如http客户端不小心请求连接websocket服务，此时服务端可以直接拒绝连接）
2. 确保服务端理解websocket连接。因为ws握手阶段采用的是http协议，因此可能ws连接是被一个http服务器处理并返回的，此时客户端可以通过Sec-WebSocket-Key来确保服务端认识ws协议。（并非百分百保险，比如总是存在那么些无聊的http服务器，光处理Sec-WebSocket-Key，但并没有实现ws协议。。。）
3. 用浏览器里发起ajax请求，设置header时，Sec-WebSocket-Key以及其他相关的header是被禁止的。这样可以避免客户端发送ajax请求时，意外请求协议升级（websocket upgrade）
4. 可以防止反向代理（不理解ws协议）返回错误的数据。比如反向代理前后收到两次ws连接的升级请求，反向代理把第一次请求的返回给cache住，然后第二次请求到来时直接把cache住的请求给返回（无意义的返回）。
5. Sec-WebSocket-Key主要目的并不是确保数据的安全性，因为Sec-WebSocket-Key、Sec-WebSocket-Accept的转换计算公式是公开的，而且非常简单，最主要的作用是预防一些常见的意外情况（非故意的）。

> 强调：Sec-WebSocket-Key/Sec-WebSocket-Accept 的换算，只能带来基本的保障，但连接是否安全、数据是否安全、客户端/服务端是否合法的 ws客户端、ws服务端，其实并没有实际性的保证。

**数据掩码的作用**

WebSocket协议中，数据掩码的作用是增强协议的安全性。但数据掩码并不是为了保护数据本身，因为算法本身是公开的，运算也不复杂。除了加密通道本身，似乎没有太多有效的保护通信安全的办法。

那么为什么还要引入掩码计算呢，除了增加计算机器的运算量外似乎并没有太多的收益（这也是不少同学疑惑的点）。

答案还是两个字：**安全**。但并不是为了防止数据泄密，而是为了防止早期版本的协议中存在的代理缓存污染攻击（proxy cache poisoning attacks）等问题。

# 重定向与请求转发的区别

一句话:重定向时浏览器上的网址改变;转发是浏览器上的网址不变

- 重定向是客户端行为,转发是服务器行为
- 重定向是两次request,请求转发是一次request