---
title: 代理-设备
date: 2022-05-03 07:33:16
categories:
- F_计算机网络
toc: true # 是否启用内容索引
---

# 代理

## 正向代理

正向代理（forward proxy）：是一个位于客户端和目标服务器之间的服务器(代理服务器)，为了从目标服务器取得内容，客户端向代理服务器发送一个请求并指定目标，然后代理服务器向目标服务器转交请求并将获得的内容返回给客户端。

比如访问外国网站技术，其用到的就是代理技术。这个过程其实和租房子很像。

<img src="/img/image-20220503164723644.png" alt="image-20220503164723644" style="zoom:67%;" />

**正向代理，其实是"代理服务器"代理了"客户端"，去和"目标服务器"进行交互。**

**作用：**

1. 突破访问限制 
2. 提高访问速度:通常代理服务器都设置一个较大的硬盘缓冲区，会将部分请求的响应保存到缓冲区
3. 隐藏客户端真实IP

## 反向代理

反向代理（reverse proxy）：是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。

比如：二房东

<img src="/img/image-20220503165033419.png" alt="image-20220503165033419" style="zoom:67%;" />

**反向代理，其实是"代理服务器"代理了"目标服务器"，去和"客户端"进行交互。**

**作用：**

1. 隐藏服务器真实IP
2. 负载均衡:根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上
3. 提高访问速度:对于静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度.
4. 提供安全保障:反向代理服务器可以作为应用层防火墙，为网站提供对基于Web的攻击行为（例如DoS/DDoS）的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加密和SSL加速（如SSL终端代理），提供HTTP访问认证等.

**正向与反向的区别：**

1、**正向代理其实是客户端的代理**，帮助客户端访问其无法访问的服务器资源。**反向代理则是服务器的代理**，帮助服务器做负载均衡，安全防护等。

2、**正向代理一般是客户端架设的**，比如在自己的机器上安装一个代理软件。而**反向代理一般是服务器架设的**，比如在自己的机器集群中部署一个反向代理服务器。

3、**正向代理中，服务器不知道真正的客户端到底是谁**，以为访问自己的就是真实的客户端。而在**反向代理中，客户端不知道真正的服务器是谁**，以为自己访问的就是真实的服务器。

4、正向代理和反向代理的作用和目的不同。**正向代理主要是用来解决访问限制问题。而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。**

## 负载均衡

Load balancing，即负载均衡，是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。它**将负载（工作任务，访问请求）进行平衡、分摊到多个操作单元（**[**服务器**](https://cloud.tencent.com/product/cvm?from=10680)**，组件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案**

OSI七层模型：

<img src="/img/image-20220503165944764.png" alt="image-20220503165944764" style="zoom:67%;" />

**负载均衡是要在网络传输中做文章的**

最常用的是**四层和七层**负载均衡。

**四层负载均衡** ：F5、LVS等

四层负载均衡工作在OSI模型的传输层，由于在传输层，只有TCP/UDP协议，这两种协议中除了包含源IP、目标IP以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器。

**七层负载均衡** ：nginx、apache等

七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用http、radius、dns等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个Web服务器的负载均衡，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。

**一、常用负载均衡算法**

负载均衡算法可以分为两类：**静态负载均衡算法**和**动态负载均衡算法**。

**（1）静态负载均衡算法包括：轮询，比率，优先权，算法分配**

**轮询（Round Robin）：**顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第2到第7 层的故障，BIG-IP 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。

<img src="/img/image-20220503170400325.png" alt="image-20220503170400325" style="zoom:50%;" />

**比率（Ratio）：**给每个**服务器**分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。

<img src="/img/image-20220503170437778.png" alt="image-20220503170437778" style="zoom:50%;" />

**优先权（Priority）：**给所有服务器分组,给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。

**算法分配**：一般采用散列算法，**通过客户端带来的某个标识经过一个标准化的散列函数进行打散分摊**。

![image-20220503170517038](/img/image-20220503170517038.png)

**（2）动态负载均衡算法包括: 最少连接数,最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。**

**最少的连接方式（Least Connection）：**传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。

<img src="/img/image-20220503170603739.png" alt="image-20220503170603739" style="zoom:50%;" />

**最快模式（Fastest）：**传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

<img src="/img/image-20220503170628061.png" alt="image-20220503170628061" style="zoom:50%;" />

**观察模式（Observed）：**连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

**预测模式（Predictive）：**BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被BIG-IP 进行检测)

**动态性能分配(Dynamic Ratio-APM)：**BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。

**动态服务器补充(Dynamic Server Act.)：**当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。

**服务质量(QoS）：**按不同的优先级对数据流进行分配。

**服务类型(ToS)：**按不同的服务类型（在Type of Field中标识）负载均衡对数据流进行分配。

**规则模式：**针对不同的数据流设置导向规则，用户可自行。

<img src="/img/image-20220503170732653.png" alt="image-20220503170732653" style="zoom: 67%;" />

**二、健康探测**

**如果节点属于“不可用”的状态的话，需要将这个节点临时从待选取列表中移除**，以提高可用性。一般常用的「健康探测」方式有3种。

 **HTTP探测**：使用Get/Post的方式请求服务端的某个固定的URL，判断返回的内容是否符合预期。一般使用Http状态码、response中的内容来判断。

**TCP探测**：基于Tcp的三次握手机制来探测指定的IP + 端口。最佳实践可以借鉴阿里云的SLB机制。

**UDP探测**：可能有部分应用使用的UDP协议。在此协议下可以通过报文来进行探测指定的IP + 端口。结果的判定方式是：在服务端没有返回任何信息的情况下，默认正常状态。否则会返回一个ICMP的报错信息。





## 动静分离

为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速 度。降低原来单个服务器的压力。

静态资源交给nginx处理，动态资源给tomcat.

## DNS

**一、定义**

。。。.三级域名.二级域名.一级域名

DNS 是域名系统（Domain Name System，缩写：DNS）是互联网的一项服务。它将域名和IP地址相互映射的一个分布式数据库。

DNS域名服务器分为三级，从上到下分别是

1. 一级为根域名服务器（Root DNS Server），全球有13个，如.com .net .cn
2. 二级为顶级域名服务器（gTLD、ccTLD、New gTLD）。gTLD国际顶级域名(如.com/.net/.org)，ccTLD国家和地区顶级域名(中国是.cn域名，日本是.jp)，New gTLD新顶级域名(如.xyz/.top/.red/.help)
3. 三级为本地域名服务器（Local DNS Server），一般是运营商的DNS



**二、DNS解析原理**

<img src="/img/image-20220503183102249.png" alt="image-20220503183102249" style="zoom:67%;" />

**简单流程**

- (1)我们在用chrome浏览器的时候，其实会先去浏览器的dns缓存里查询，dns缓存中没有，再去调用gethostbyname函数
- (2)gethostbyname函数在试图进行DNS解析之前首先检查域名是否在本地 Hosts 里，如果没找到再去DNS服务器上查

**大致流程**

解析流程就是**分级查询**

1. 先在本机的DNS里头查，如果有就直接返回了
2. 本机DNS里头发现没有，就去根服务器里查。
3. 本机的DNS接到又会向`com`域的DNS服务器发送查询消息。以此类推，只要重复前面的步骤，就可以顺藤摸瓜找到目标DNS服务器

**详细流程0**

1） 浏览器缓存　　当用户通过浏览器访问某域名时，浏览器首先会在自己的缓存中查找是否有该域名对应的IP地址（若曾经访问过该域名且没有清空缓存便存在）；　　
2） 系统缓存　　当浏览器缓存中无域名对应IP则会自动检查用户计算机系统Hosts文件DNS缓存是否有该域名对应IP；　　
3） 路由器缓存　　当浏览器及系统缓存中均无域名对应IP则进入路由器缓存中检查，以上三步均为客服端的DNS缓存；　　
4） ISP（互联网服务提供商）DNS缓存　　当在用户客服端查找不到域名对应IP地址，则将进入ISP DNS缓存中进行查询。比如你用的是电信的网络，则会进入电信的DNS缓存服务器中进行查找；
5） 根域名服务器　　当以上均未完成，则进入根服务器进行查询。全球仅有13台根域名服务器，1个主根域名服务器，其余12为辅根域名服务器。根域名收到请求后会查看区域文件记录，若无则将其管辖范围内顶级域名（如.com）服务器IP告诉本地DNS服务器；　　
6） 顶级域名服务器　　顶级域名服务器收到请求后查看区域文件记录，若无则将其管辖范围内主域名服务器的IP地址告诉本地DNS服务器；　　
7） 主域名服务器　　主域名服务器接受到请求后查询自己的缓存，如果没有则进入下一级域名服务器进行查找，并重复该步骤直至找到正确纪录；　　
8）保存结果至缓存　　本地域名服务器把返回的结果保存到缓存，以备下一次使用，同时将该结果反馈给客户端，客户端通过这个IP地址与web服务器建立链接。

**详细流程1**

- 1、用户请求通过浏览器输入要访问网站的地址，例如：www.51cto.com。浏览器会在自己的缓存中查找URL对应IP地址。如果之前访问过，保存了这个URL对应IP地址的缓存，那么就直接访问IP地址。如果没有缓存，进入到第2步。
- 2、通过计算机本地的Host文件配置，可以设置URL和IP地址的映射关系。比如windows下是通过C:windwossystem32driveretchosts文件来设置的，linux中则是/etc/named.confg文件。这里查找本地的Host文件，看是有IP地址的缓存。如果在文件中依旧没有找到映射关系，进入第3步。
- 3、请求Local DNS Server，通过本地运营商获取URL和IP的映射关系。如果在校园网，DNS服务器就在学校，如果是小区网络，DNS服务器是运营商提供的。总之这个服务器在物理位置上离发起请求的计算机比较近。Local DNS Server缓存了大量的DNS解析结果。由于它的性能较好，物理上的距离又比较近，它通常会在很短的时间内返回指定域名的解析结果。80%的DNS解析需求在这一步就满足了。如果在这一步还是没有完成DNS解析，进入第4步
- 4、通过Root DNS Server进行解析，ROOT DNS Server会根据请求的URL 返回给Local DNS Server顶级域名服务器的地址。例如：查询的是”.com”的域名，就查询 gTL对应的域名服务器的地址。
- 5、返回顶级域名服务器的地址以后，访问对应的顶级域名服务器（gTLD、ccTLD、New gTLD），并且返回Name Server服务器地址。这个Name Server就是网站注册的域名服务器，上面包含了网站URL和IP的对应信息。例如你在某个域名服务提供商申请的域名，这个域名就由他们的服务器来解析。这个Name Server是由域名提供商维护的。
- 6、Name Server会把指定域名的A记录或者CNAME返回给Local DNS Server，并且设置一个TTL。

```
A (Address) 记录是用来指定主机名（或域名）对应的IP地址记录。用户可以将该域名下的网站服务器指向到自己的web server上。同时也可以设置您域名的二级域名。
CNAME：别名记录。这种记录允许您将多个名字映射到另外一个域名。通常用于同时提供WWW和MAIL服务的计算机。例如，有一台计算机名为“host.mydomain.com”（A记录）。它同时提供WWW和MAIL服务，为了便于用户访问服务。服务商从方便维护的角度，一般也建议用户使用CNAME记录绑定域名的。如果主机使用了双线IP，显然使用CNAME也要方便一些。
TTL（Time To Live）：也就是设置这个DNS解析在Local DNS Server上面的过期时间。超过了这个过期时间，URL和IP的映射就会被删除，需要获取还要请求Name Server。
```

- 7、如果此时获取的是A记录，那么就可以直接访问网站的IP了。但是通常来说大型的网站都会返回CNAME，然后将其传给GTM Server。

  ```
  GTM（Global Traffic Manager的简写）即全局流量管理，基于网宿智能DNS、分布式监控体系，实现实时故障切换及全球负载均衡，保障应用服务的持续高可用性。传给GTM的目的就是希望通过GTM的负载均衡机制，帮助用户找到最适合自己的服务器IP。
  
  也就是离自己最近，性能最好，服务器状态最健康的。而且大多数的网站会做CDN缓存，此时就更需要使用GTM帮你找到网络节点中适合你的CDN缓存服务器。
  ```

- 8、找到[CDN缓存](https://link.segmentfault.com/?enc=ENK6LzHAPzM2q99SvmavYA%3D%3D.dUPiDfO0w7RVP3jZYcAg4%2B4vSD2x64UVGCgVuGFTr4nGna5Hk6f3X1DFkrmFAydBrmcqD1AgdU%2BSvwsqfKGnwAsoV22jsCWBetVpzL0mAo5n0vY7MNjpB4ekipdbvrcuXYkTtNg2GQ6jPgE%2B1d%2BNT05qGKCxliyU3Csqq14JohvC7BNgf66jWy17iExOAMhzHeH1T%2Fh2ujX05p7re0vEDNeHgmWk2cxMqY%2BwX70a%2BeHLCD1mtdqI0tOfiAIlK3yCv%2F0tk7ORD7pTCMmedAi4YWMqFo40ETBnWTqXy6E0pLD3ENrFHhgJReGgdXjeFvzP)服务器以后，可以直接从服务器上面获取一些静态资源，例如：HTML、CSS、JS和图片。但是一些动态资源，例如商品信息，订单信息，需要通过第9步。

- 9、对于没有缓存的动态资源需要从应用服务器获取，在应用服务器与互联网之间通常有一层负载均衡器负责反向代理。有它路由到应用服务器上

**三、DNS上用UDP还是TCP协议**

**区域传送用TCP协议**

DNS的规范规定了2种类型的DNS服务器，一个叫主DNS服务器，一个叫辅助DNS服务器。在一个区中主DNS服务器从自己本机的数据文件中读取该区的DNS数据信息，而辅助DNS服务器则从区的主DNS服务器中读取该区的DNS数据信息。当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，这就叫做区传送（zone transfer）。 这种情况下，使用TCP协议。

因为TCP协议可靠性好啊！你要从主DNS上复制内容啊，你用不可靠的UDP？ 因为TCP协议传输的内容大啊，你用最大只能传512字节的UDP协议？万一同步的数据大于512字节，你怎么办？

**域名解析用UDP协议**

因为UDP快啊！UDP的DNS协议只要一个请求、一个应答就好了。而使用基于TCP的DNS协议要三次握手、发送数据以及应答、四次挥手。但是UDP协议传输内容不能超过512字节。不过客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。

## CDN

**介绍**

内容分发网络（Content Delivery Network，简称CDN）是建立并覆盖在承载网之上，由分布在不同区域的边缘节点服务器群组成的分布式网络。*依靠部署在各地的边缘服务器，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度。*

**应用范围**

1. 加速网站的访问
2. 实现跨运营商、跨地域的全网覆盖
3. 保障网站安全
4. 异地备援
5. 节约成本
6. 让你更专注业务本身

2.实现跨运营商、跨地域的全网覆盖

互联不互通、区域ISP地域局限、出口带宽受限制等种种因素都造成了网站的区域性无法访问。CDN加速可以覆盖全球的线路，通过和运营商合作，部署IDC资源，在全国骨干节点商，合理部署CDN边缘分发存储节点，充分利用带宽资源，平衡源站流量。阿里云在国内有500+节点，海外300+节点，覆盖主流国家和地区不是问题，可以确保CDN服务的稳定和快速。

3.保障网站安全

CDN的负载均衡和分布式存储技术，可以加强网站的可靠性，相当无无形中给你的网站添加了一把保护伞，应对绝大部分的互联网攻击事件。防攻击系统也能避免网站遭到恶意攻击。

4.异地备援

当某个服务器发生意外故障时，系统将会调用其他临近的健康服务器节点进行服务，进而提供接近100%的可靠性，这就让你的网站可以做到永不宕机。

5.节约成本

投入使用CDN加速可以实现网站的全国铺设，你根据不用考虑购买服务器与后续的托管运维，服务器之间镜像同步，也不用为了管理维护技术人员而烦恼，节省了人力、精力和财力。

6.专注业务本身

CDN加速厂商一般都会提供一站式服务，业务不仅限于CDN，还有配套的云存储、大数据服务、视频云服务等，而且一般会提供7x24运维监控支持，保证网络随时畅通，你可以放心使用。并且将更多的精力投入到发展自身的核心业务之上。

**核心流程**

<img src="/img/image-20220514125920545.png" alt="image-20220514125920545" style="zoom:67%;" />

1. 当用户点击网站页面上的内容URL，经过本地DNS系统解析，DNS 系统会最终将域名的解析权交给 [CNAME](https://en.wikipedia.org/wiki/CNAME_record) 指向的 CDN 专用 DNS 服务器。
2. CDN 的 DNS 服务器将 CDN 的全局负载均衡设备 IP 地址返回用户。
3. 用户向 CDN 的全局负载均衡设备发起内容 URL 访问请求。
4. CDN 全局负载均衡设备根据用户 IP 地址，以及用户请求的内容URL，选择一台用户所属区域的区域负载均衡设备，告诉用户向这台设备发起请求。
5. 基于以下这些条件的综合分析之后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的IP地址：
6. 根据用户 IP 地址，判断哪一台服务器距用户最近；
7. 根据用户所请求的 URL 中携带的内容名称，判断哪一台服务器上有用户所需内容；
8. 查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。
9. 全局负载均衡设备把服务器的 IP 地址返回给用户。
10. 用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。

DNS 服务器根据用户 IP 地址，将域名解析成相应节点的缓存服务器IP地址，实现用户就近访问。使用 CDN 服务的网站，只需将其域名解析权交给 CDN 的全局负载均衡（GSLB）设备，将需要分发的内容注入 CDN，就可以实现内容加速了。

### 淘宝CDN架构

<img src="/img/image-20220514130352357.png" alt="image-20220514130352357" style="zoom:67%;" />

淘宝整个图片的访问链路有三级缓存（客户端本地、CDN L1、CDN L2），所有图片都持久化的存储到OSS中。真正处理图片的是img-picasso系统，它的功能比较复杂，包括从OSS读取文件，对图片尺寸进行缩放，编解码，所以机器成本比较高。

CDN的缓存分成2级，合理的分配L1和L2的比例，一方面，可以通过一致性hash的手段，在同等资源的情况下，缓存更多内容，提升整体缓存命中率；另一方面，可以平衡计算和IO，充分利用不同配置的机器的能力。

**用户访问图片的过程如下**：
（1）用户通过手机淘宝来搜索商品或者查看宝贝详情。
（2）详情/搜索/推荐通过调用商品中心返回商品的图片URL。
（3）客户端本地如果有该图片的缓存，则直接渲染图片，否则执行下一步。
（4）从CDN L1回源图片，如果L1有该图片的缓存，则客户端渲染图片，同时缓存到本地，如果L1没有缓存，则执行下一步。
（5）从CDN L2回源图片，如果L2有该图片的缓存，则客户端渲染图片，同时CDN L1及客户端缓存图片内容，如果CDN L2没有缓存该图片，则执行下一步。
（6）从图片空间回源图片，图片空间会从OSS拉取图片源文件，按要求进行尺寸缩放，然后执行编解码，返回客户端能够支持的图片内容，之后客户端就可以渲染图片，同时CDN的L1、L2以及客户端都会缓存图片内容。

**频繁换图带来的问题**

<img src="/img/image-20220514130526921.png" alt="image-20220514130526921" style="zoom: 50%;" />

**2个问题**

（1）CDN及手机淘宝原本缓存的图片内容失效了，用户访问图片会全部回源到img-picasso。
（2）由于更改了商品的字段，交易的核心应用（购物车和商品中心）的缓存也失效了，用户浏览及购物时，对商品的访问会走到db。

源站img-picasso处理图片，以及查询商品DB，都是非常消耗资源的。CDN及商品的缓存命中率降低后，对源站img-picsasso以及db会产生巨大的压力。

拿CDN缓存为例，简单计算一下，CDN平时的命中率是98%，假设命中率降低1个点，对源站的压力就会增加1/3（原本承担2%的流量，现在需要承担3%的流量），意味着img-picasso需要扩容1/3。如果全网一半的图片都同时变化，cdn的命中率降到50%，对img-picasso的访问量就会增加25倍，这个扩容成本肯定没法接受。

**2个解决方案**

（1）改图保持图片URL不变，可以避免商品链路的缓存失效。
（2）在访问高峰到来之前，提前预热图片到CDN，可以避免CDN缓存失效对源站的压力。

**换图方案落地**

<img src="/img/image-20220514130822460.png" alt="image-20220514130822460" style="zoom:50%;" />

图片内容发生变化时，执行下面2个操作：
（1）更新OSS内容：使用新的图片内容替换OSS中老的图片内容
（2）刷新CDN缓存：清除CDN之前缓存的图片内容

这样，用户再次访问图片时，发现CDN没有缓存，就会回源到img-picasso，从OSS拉取新的图片内容。由于图片URL没有变化，就不必去更新商品中心的图片链接，这样商品链路的缓存可以保持不变。在真正实施这个方案的过程中，遇到了几个问题

**1.OSS三地同步**

淘宝的图片空间，承载了淘系所有图片的上下行稳定性保障，为了保障高可用，一份资源会存储到三地OSS。图片上传时，默认只上传一地，利用OSS的能力，自动同步到另外两地。
     但是使用URL不变方案，CDN缓存已经清除完成后，如果另外2地的OSS还未同步完成，用户访问后，就会回源到旧的图片内容，发现[图片](https://www.zhihu.com/search?q=图片&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1604554133})内容没有变化。
      针对该问题，我们将异步同步OSS软链的模式，改成三地同步建软链，三地都返回成功后，再去清除CDN缓存，这就保证了用户访问的图片一定是最新的内容。

<img src="/img/image-20220514142211760.png" alt="image-20220514142211760" style="zoom: 67%;" />

**2.图片尺寸收敛**

同一张商品图片会用于不同的场景坑位展现，不同的坑位对图片的尺寸有不同的要求。为此，图片空间提供了一项功能，可以方便的生成不同尺寸的缩率图。只需要访问图片时，给图片增加不同的后缀，img-picasso源站就可以按要求进行图片进行缩放。
由于历史原因，之前对缩放的尺寸种类没有限制，导致CDN上的图片后缀格式多达2400种+，TOP6格式覆盖率46%，TOP15格式覆盖率64%。这意味着，一张图片，在cdn上最多可能有2400+个不同的url，当图片内容变化后，要把这些缓存全部清掉，才能保证所有用户看到的图片都是新内容。

最后把2000多种格式收敛到6种主要格式，CDN清除缓存才变得可行

**3.多副本清除CDN缓存**

通过图片尺寸收敛，每张图片只需要清除6个不同的url就可以了，那能不能进一步提升刷新效率呢？
为此，阿里云CDN为我们提供了多副本刷新的解决方案：每种不同后缀的图片，作为图片的一个副本，在CDN的swift层增加一层KV结构，存储url和不同副本的映射关系，清除缓存时，可以通过该结构找到所有副本，实现快速清除所有副本。这样，每张图片，我们只需要调用一次CDN清除缓存接口就可以了，极大提升了CDN缓存刷新效率

**4.图片域名收敛**

<img src="/img/image-20220514142440906.png" alt="image-20220514142440906" style="zoom:67%;" />

淘系的图片域名有300多种，主要有下面2个原因：
（1）图片完整的链接太长，所以存储时经常只存最后一段，业务自己来拼域名，很多业务就自己申请了一个图片域名来拼。
（2）PC时代，浏览器对同一域名下的并发请求数是有限制的，不同浏览器不一样，一般6个左右。

为了突破该限制，一些业务就会申请多个域名，随机的拼不同的域名。前面我们讲过，CDN的缓存是跟域名绑定的，不管是缓存命中还是缓存清除，都只能针对一个域名。我们显然不可能改一张图，就去对300个域名调用CDN刷新。于是我们考虑对图片域名进行收敛，使得用户对图片的访问都路由到同一个域名，我们希望将所有的图片访问统一收敛到http://picasso.alicdn.com，具体实现方式如下：
（1）对于手淘和猫客客户端，图片访问都收口在图片库，我们推进图片库进行改造，符合一定规则的url，统一收敛到http://picasso.alicdn.com，实现了域名的一刀切。
（2）对于PC浏览器端，就比较麻烦了，没有统一收口的地方。我们只能退而求其次，针对访问最多的6大域名，在cdn上配置域名转发规则，重定向到picasso域名。

通过这种方式，我们实现了全网99%以上的图片访问流量都路由到picasso域名，图片内容发生变化时，通过清除picasso域名的cdn缓存，就能保证基本所有的场景都能看到新的图片内容。

**解決：客户端及浏览器缓存落地**

通过多副本和图片域名收敛，cdn的缓存问题得到了解决。但在cdn之上，用户图片访问首先是来自客户端或者浏览器，这里也会有一层缓存。
大家知道，浏览器的缓存都遵循标准的http max-age协议，指定该header后，到了时间图片就会失效，访问到新的图片。所以我们可以在源站img-picasso回源给cdn时，添加max-age协议头，值为1分钟，cdn会原封不动的透给浏览器，这样浏览器就可以实现1分钟内图片缓存失效，重新到cdn拉新的图片资源。
对于手机淘宝客户端，我们在原有的LRU缓存机制之上，另外支持标准的http协议。这样，手机淘宝也实现了1分钟内图片缓存失效。

**提前预热CDN图片**

通过改图保持图片URL不变，我们解决了改图对商品链路缓存的影响。但是，图片变化时，虽然URL没有变，但我们清除了CDN缓存，导致用户访问时还是会回源到img-picasso源站，所以对图片源站的压力依然存在。

我们发现，商品的价格变化大部分发生在大促节奏变化的时刻，基于这个特点，我们通过提前合成图片，提前预热到CDN，可以实现图片切换瞬间生效，同时对源站没有压力。

具体方案如下：
（1）提前合成多波段图片：我们知道大促期间商家集中换图的时间点后，按这些时间点把图片的展示分成多个波段，每个波段图片提前合成，并提前将图片URL写入到商品中心扩展结构中。
（2）图片访问路由：营销系统根据配置的大促氛围切换计划，告诉鹿班图片二方包，当前是哪个波段，鹿班根据当前波段及场景，返回正确的图片URL给各个场景。
（3）图片渲染：各个场景拿到图片URL后，结合自身的业务逻辑，决定是否要展现该图片。
（4）CDN图片预热：为了避免图片集中切换时，把源站击垮，我们会在集中切换前把这些冷图片内容预热到CDN。
（5）波段内图片变化：提前合成各个波段图片后，商家可能会临时发券/改价，导致商品价格再次变化，对于这类换图需求，为了避免更新商品中心的图片URL，我们通过本文上一章节刷CDN缓存的方式实现。

**其他**

其实，CDN本身就是一种DNS劫持，只不过是良性的。 不同于黑客强制DNS把域名解析到自己的钓鱼IP上，CDN则是让DNS主动配合，把域名解析到临近的服务器上。

**劫持通常分为两类：**

- 域名劫持，又称DNS劫持，通常是指域名指向到非正常IP（恶意IP），该恶意IP通过反向代理的方式，在能返回网页正常内容的情况，可能插入恶意代码、监听网民访问、劫持敏感信息等操作。通常验证一个域名是否被劫持的方法是PING一个域名，如果发现PING出来的IP不是您的服务器真实IP，则可以确定被劫持了（当然如果使用了知道创宇云安全等安全加速平台，得到的IP为平台IP，并非劫持）
- 数据劫持，通常由电信运营商中某些员工等勾结犯罪分子，在公网中进行数据支持，插入，此类情况极隐蔽，不会改变用户域名解析IP，而是直接数据流经运营商宽带时在网页中挺入内容，此类情况，建议网页启用HTTPS加密，可以解决这一问题（通信是加密的，运营商无法插入恶意内容）

**高仿、洗流量**：CDN 可以通过分流 ，洗掉来自Dos 大部分的攻击 。

**参考**

[阿里淘宝CDN方案](https://www.zhihu.com/question/36514327)

# Nginx

## 简介

Nginx是一个高性能静态HTTP服务器、反向代理服务器、虚拟主机(正向代理)，也是一个 IMAP/POP3/SMTP 代理 [服务器](http://www.itbbu.com/tag/服务器)

**Nginx** 专为性能优化而开发，性能是其最重要的考量，实现上非常注重效率，能经受高负载的考验，最大能支持 50000 个并发连接数。 Nginx 还支持热部署，它的使用特别容易，几乎可以做到 7x24 小时不间断运行。 Nginx 的网站用户有：百度、淘宝、京东、腾讯、新浪、网易等。

## 特点

- 第一，它可以支持 5W 高并发连接;
- 第二，内存消耗少;
- 第三，成本低。

1、热部署
我个人觉得这个很不错。在master管理进程与worker工作进程的分离设计，使的Nginx具有热部署的功能，那么在7×24小时不间断服务的前提下，升级Nginx的可执行文件。也可以在不停止服务的情况下修改配置文件，更换日志文件等功能。

2、可以高并发连接
这是一个很重要的一个特性！在这一个互联网快速发展， 互联网用户数量不断增加， 一些大公司、网站都需要面对高并发请求，如果有一个能够在峰值顶住10万以上并发请求的Server，肯定会得到大家的青睐。理论上，Nginx支持的并发连接上限取决于你的内存，10万远未封顶。

3、低的内存消耗
在一般的情况下，10000个非活跃的HTTP Keep-Alive 连接在Nginx中仅消耗2.5M的内存，这也是Nginx支持高并发连接的基础。

4、处理响应请求很快
在正常的情况下，单次请求会得到更快的响应。在高峰期，Nginx可以比其他的Web服务器更快的响应请求。

5、具有很高的可靠性
Nginx是一个高可靠性的Web服务器，这也是我们为什么选择Nginx的基本条件，现在很多的网站都在使用Nginx，足以说明Nginx的可靠性。高可靠性来自其核心框架代码的优秀设计、模块设计的简单性；并且这些模块都非常的稳定。

## 四大作用

- 静态HTTP服务器
- 虚拟主机(正向代理)
- 反向代理
- 负债均衡

### **静态HTTP服务器**

<img src="/img/image-20220518072613911.png" alt="image-20220518072613911" style="zoom:67%;" />

Nginx是一个HTTP服务器，可以将服务器上的静态文件（如HTML、图片）通过HTTP协议展现给客户端。

为了加快网站的解析速度，可以把静态页面和动态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。

```
server {  
    listen 80; # 端口号  
    location / {  
        root /usr/share/nginx/html; # 静态文件路径  
    }  
}  
```

### **虚拟主机(正向代理)**

<img src="/img/image-20220518072515310.png" alt="image-20220518072515310" style="zoom:67%;" />

有的网站访问量大，需要负载均衡。然而并不是所有网站都如此出色，有的网站，由于访问量太小，需要节省成本，将多个网站部署在同一台服务器上。

例如将www.aaa.com和www.bbb.com两个网站部署在同一台服务器上，两个域名解析到同一个IP地址，但是用户通过两个域名却可以打开两个完全不同的网站，互相不影响，就像访问两个服务器一样，所以叫两个虚拟主机。

正向代理来进行上网等功能。

```
server {  
    listen 80 default_server;  
    server_name _;  
    return 444; # 过滤其他域名的请求，返回444状态码  
}  
 
server {  
    listen 80;  
    server_name www.aaa.com; # www.aaa.com域名  
    location / {  
        proxy_pass http://localhost:8080; # 对应端口号8080  
    }  
}  
server {  
    listen80;  
    server_name www.bbb.com; # www.bbb.com域名  
    location / {  
        proxy_pass http://localhost:8081; # 对应端口号8081  
    } 
}  
```

在服务器8080和8081分别开了一个应用，客户端通过不同的域名访问，根据server_name可以反向代理到对应的应用服务器。

虚拟主机的原理是通过HTTP请求头中的Host是否匹配server_name来实现的。

另外，server_name配置还可以过滤有人恶意将某些域名指向你的主机服务器。

### **反向代理**

<img src="/img/image-20220518072532385.png" alt="image-20220518072532385" style="zoom:67%;" />

客户端本来可以直接通过HTTP协议访问某网站应用服务器，网站管理员可以在中间加上一个Nginx，客户端请求Nginx，Nginx请求应用服务器，然后将结果返回给客户端，此时Nginx就是反向代理服务器。

客户端对代理服务器是无感知的，客户端不需要做任何配置，用户只请求反向代理服务器，反向代理服务器选择目标服务器，获取数据后再返回给客户端。反向代理服务器和目标服务器对外而言就是一个服务器，只是暴露的是代理服务器地址，而隐藏了真实服务器的IP地址。

```
server {  
    listen 80;  
    location / {  
        proxy_pass http://192.168.20.1:8080; # 应用服务器HTTP地址  
    }  
}  
```

### **负载均衡**

<img src="/img/image-20220518072550109.png" alt="image-20220518072550109" style="zoom:67%;" />

当网站访问量非常大，网站站长开心赚钱的同时，也摊上事儿了。因为网站越来越慢，一台服务器已经不够用了。于是将同一个应用部署在多台服务器上，将大量用户的请求分配给多台机器处理。同时带来的好处是，其中一台服务器万一挂了，只要还有其他服务器正常运行，就不会影响用户使用。

将原先请求集中到单个服务器上的情况改为增加服务器的数量，然后将请求分发到各个服务器上，将负载分发到不同的服务器，即负载均衡。

Nginx可以通过反向代理来实现负载均衡。

```
upstream myserver {   
    server 192.167.4.32:5000;
    server 192.168.4.32:8080;     
}           

server {     
    listen       80;   #监听端口   
    server_name  192.168.4.32;   #监听地址   
 
    location  / {             
        root html;  #html目录        
        index index.html index.htm;  #设置默认页    
        proxy_pass  http://myserver;  #请求转向 myserver 定义的服务器列表      
    }
} upstream myserver {   
    server 192.167.4.32:5000;
    server 192.168.4.32:8080;     
}           

server {     
    listen       80;   #监听端口   
    server_name  192.168.4.32;   #监听地址   
 
    location  / {             
        root html;  #html目录        
        index index.html index.htm;  #设置默认页    
        proxy_pass  http://myserver;  #请求转向 myserver 定义的服务器列表      
    }
} 
```

#### 常用的4种nginx负载均衡算法

**1.轮询**

轮询是默认的方式，每个请求按时间顺序逐一分配到不同的后端服务器上。如果后台服务器上某一台宕机了，它可以自动剔除。

缺点：可靠性低和负载分配不均衡。适用于图片服务器和静态页面服务器集群。

**2. 加权轮询（wight）**

指定轮询的几率，wight和访问比率成正比，用于后台服务器性能不均匀的情况。

```
upstream linuxidc{       
   server 10.0.0.77 weight=5;       
   server 10.0.0.88 weight=10; 
}复制代码
```

**3. ip_hash**

根据每个请求的ip的hash结果分配，因此每个固定ip能访问到同一个后端服务器，可以解决session问题。

```
upstream favresin{      
    ip_hash;      
    server 10.0.0.10:8080;       
    server 10.0.0.11:8080; 
}复制代码
```

**4. fair（第三方）**

按照后端服务器的响应时间来分配请求，响应时间短的优先分配。

```
 upstream favresin{            
      server 10.0.0.10:8080;       
      server 10.0.0.11:8080;       
      fair; 
}复制代码
```

**5. url_hash（第三方）**

按照访问url的hash结果来分配请求，每个固定的url访问同一个后端服务器。如果后端服务器是缓存时效率高。

```
 upstream resinserver{       
      server 10.0.0.10:7777;       
      server 10.0.0.11:8888;       
      hash $request_uri;       
      hash_method crc32; 
}
例：在upstream中加入hash语句，hash_method是使用的hash算法。
复制代码
```

在upstream模块中，可以通过server命令指定后端服务器的IP地址和端口，同时还可以设置每台后端服务器在负载均衡调度中的状态，

**upstream参数解析**

- upstream可以为每个设备设置状态值
- down：表示当前的server暂时不参与负载
- weight：默认为1，wight越大，负载的权重越大。
- max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误。
- fail_timeout：max_fails此失败后，暂停的时间。
- backup：其他所有非backup机器宕或者忙的时候，请求backup的机器。

示例：

```
tips:
upstream bakend{ #定义负载均衡设备的Ip及设备状态  
  ip_hash;  
  server 192.0.0.1:8090 weight=5 max_fails=3 fail_timeout=20s;
  server 127.0.0.1:9090 down; 
  server 127.0.0.1:8080 weight=2;    
  server 127.0.0.1:6060;  
  server 127.0.0.1:7070 backup;  
}复制代码
```

#### 常见的几种负载均衡算法

**1、轮询法**

将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。

**2、加权轮询法**

不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。

**3、随机法**

通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，

其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。

**4、加权随机法**

与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。

**5、哈希算法**

- 普通哈希：源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。
- 一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。一致性hash算法就是把每台server分成v个虚拟节点，再把所有虚拟节点（n*v）随机分配到一致性哈希的圆环上，这样所有的用户从自己圆环上的位置顺时针往下取到第一个vnode就是自己所属的节点。当此节点存在故障时，再顺时针取下一个作为替代节点

**6、最小连接数法**

最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前

积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。

**7、IP地址散列**

通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处理。

**8、URL散列**

通过管理客户端请求URL信息的散列，将发送至相同URL的请求转发至同一服务器的算法。

#### 四层和七层负载均衡

四层负载均衡工作在OSI模型的**传输层**，主要工作是转发，它在接收到客户端的流量以后通过修改数据包的地址信息将流量转发到应用服务器。

七层负载均衡工作在OSI模型的**应用层**，因为它需要解析应用层流量，所以七层负载均衡在接到客户端的流量以后，还需要一个完整的TCP/IP协议栈。七层负载均衡会与客户端建立一条完整的连接并将应用层的请求流量解析出来，再按照调度算法选择一个应用服务器，并与应用服务器建立另外一条连接将请求发送过去，因此七层负载均衡的主要工作就是代理。

**软硬件**

1）四层的负载均衡就是基于IP+端口的负载均衡：

> 对应的负载均衡器称为四层交换机（L4 switch），主要分析IP层及TCP/UDP层，实现四层负载均衡。此种负载均衡器不理解应用协议（如HTTP/FTP/MySQL等等）。

**实现四层负载均衡的软件有：**

- F5：硬件负载均衡器，功能很好，但是成本很高。
- lvs：重量级的四层负载软件
- nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活
- haproxy：模拟四层转发，较灵活

2）七层的负载均衡就是基于虚拟的URL或主机IP的负载均衡

> 对应的负载均衡器称为七层交换机（L7 switch），除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息，实现七层负载均衡。此种负载均衡器能理解应用协议。

**实现七层负载均衡的软件有：**

- haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；
- nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；
- apache：功能较差
- Mysql proxy：功能尚可。

总的来说，一般是lvs做4层负载；nginx做7层负载；haproxy比较灵活，4层和7层负载均衡都能做。

**技术原理上的区别：**

所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

> 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。

<img src="/img/image-20220519072131243.png" alt="image-20220519072131243" style="zoom:67%;" />

所谓七层负载均衡，也称为“内容交换”，也就是主要通过**报文中的真正有意义的应用层内容**，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

> 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。

**具体实现：**

（1）目前负载均衡系统有Nginx、LVS、F5，即：

- Nginx是软件的7层负载均衡，
- LVS是内核的4层负载均衡，
- F5是硬件的4层负载均衡。

（2）软件和硬件的区别在于性能，硬件远远高于软件，即：

- Nginx的性能是万级的，一般的Linux服务器上安装一个Nginx能达到每秒5万并发请求；
- 而F5的性能能达到百万级，从200万每秒到800万每秒都有，不过价格很贵。

（3）4层和7层的区别在于协议和灵活性，即：

- Nginx是7层的，它支持HTTP等协议，
- 而LVS和F5是4层协议，它们和协议无关，几乎所有应用都可以做。



### 高可用

<img src="/img/image-20220518072705600.png" alt="image-20220518072705600" style="zoom:67%;" />

为了提高系统的可用性和容错能力，可以增加nginx服务器的数量，当主服务器发生故障或宕机，备份服务器可以立即充当主服务器进行不间断工作。

参考

- [从原理到实战，彻底搞懂 Nginx！入门篇](https://zhuanlan.zhihu.com/p/101961241)
- [从原理到实战，彻底搞懂 Nginx！中级篇](https://zhuanlan.zhihu.com/p/102528726)

# 设备

## 集线器（HUB）

集线器起到了一个将网线集结起来的作用，实现最初级的网络互通。集线器是通过网线直接传送数据的，我们说他工作在**物理层**。

类似网吧的CS精英。

**第1层（物理层）**上运行

<img src="/img/image-20220504160952342.png" alt="image-20220504160952342" style="zoom:50%;" />

## 交换机

集线器会广播所有消息，但我只需要告知某人消息，这就需要交换机

将资料从A的电脑传送到C的电脑中，而不让小B、小D和小E收到。也就是说，这台设备解决了冲突的问题，实现了任意两台电脑间的互联，大大地提升了网络间的传输速度，我们把它叫做交换机。由于交换机是根据网口地址传送信息，比网线直接传送多了一个步骤，我们也说交换机工作在**数据链路层**。

**第2层（数据链路层）**运行

<img src="/img/image-20220504161205348.png" alt="image-20220504161205348" style="zoom:50%;" />

## 路由器

其他村也想加入进来，路由器就出现了。路由器上有 WAN 口和 LAN 接口，而交换机没有这些接口。

**第3层（网络层）**上运行

<img src="/img/image-20220504161317346.png" alt="image-20220504161317346" style="zoom:67%;" />

## 猫

猫的学名叫[调制解调器](https://www.zhihu.com/search?q=调制解调器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A402261894})，它的作用是将数字信号（电脑想要发送的信息）转换成模拟信号（网线中的电流脉冲）从而使信息在网线中传输。

目前的家用路由器一般都是路由猫，即路由器兼顾了猫和简单交换机的功能。

**小结**

用快递解释：

数据帧：快递

二层MAC地址:你的身份证号，全球唯一

三层IP地址:你的当前的住宅地址，你随时可能会搬去其他地址住

额外的规则:一个住宅地址只能住一个人，否则会导致收发快递不正常

[交换机](https://www.zhihu.com/search?q=交换机&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A21177598})：给你派件的快递员，但是只认身份证号的数字(MAC)，不认地址上的中文(IP)

路由器：物流公司的集散中心，占有一个身份证号(MAC)，同时占有一个住宅地址(IP)

[载波](https://www.zhihu.com/search?q=载波&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A21177598})：运输快递的火车/飞机/船

猫：将快递装上/卸下火车/飞机/船的地方
