---
title: Nginx入门
date: 2022-05-18 07:33:16
categories:
- F_计算机网络
toc: true # 是否启用内容索引
---

# 简介

Nginx是一个高性能静态HTTP服务器、反向代理服务器、虚拟主机(正向代理)，也是一个 IMAP/POP3/SMTP 代理 [服务器](http://www.itbbu.com/tag/服务器)

**Nginx** 专为性能优化而开发，性能是其最重要的考量，实现上非常注重效率，能经受高负载的考验，最大能支持 50000 个并发连接数。 Nginx 还支持热部署，它的使用特别容易，几乎可以做到 7x24 小时不间断运行。 Nginx 的网站用户有：百度、淘宝、京东、腾讯、新浪、网易等。

# 特点

- 第一，它可以支持 5W 高并发连接;
- 第二，内存消耗少;
- 第三，成本低。

1、热部署
我个人觉得这个很不错。在master管理进程与worker工作进程的分离设计，使的Nginx具有热部署的功能，那么在7×24小时不间断服务的前提下，升级Nginx的可执行文件。也可以在不停止服务的情况下修改配置文件，更换日志文件等功能。

2、可以高并发连接
这是一个很重要的一个特性！在这一个互联网快速发展， 互联网用户数量不断增加， 一些大公司、网站都需要面对高并发请求，如果有一个能够在峰值顶住10万以上并发请求的Server，肯定会得到大家的青睐。理论上，Nginx支持的并发连接上限取决于你的内存，10万远未封顶。

3、低的内存消耗
在一般的情况下，10000个非活跃的HTTP Keep-Alive 连接在Nginx中仅消耗2.5M的内存，这也是Nginx支持高并发连接的基础。

4、处理响应请求很快
在正常的情况下，单次请求会得到更快的响应。在高峰期，Nginx可以比其他的Web服务器更快的响应请求。

5、具有很高的可靠性
Nginx是一个高可靠性的Web服务器，这也是我们为什么选择Nginx的基本条件，现在很多的网站都在使用Nginx，足以说明Nginx的可靠性。高可靠性来自其核心框架代码的优秀设计、模块设计的简单性；并且这些模块都非常的稳定。

# 四大作用

- 静态HTTP服务器
- 虚拟主机(正向代理)
- 反向代理
- 负债均衡

## **静态HTTP服务器**

<img src="/img/image-20220518072613911.png" alt="image-20220518072613911" style="zoom:67%;" />

Nginx是一个HTTP服务器，可以将服务器上的静态文件（如HTML、图片）通过HTTP协议展现给客户端。

为了加快网站的解析速度，可以把静态页面和动态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。

```
server {  
    listen 80; # 端口号  
    location / {  
        root /usr/share/nginx/html; # 静态文件路径  
    }  
}  
```

## **虚拟主机(正向代理)**

<img src="/img/image-20220518072515310.png" alt="image-20220518072515310" style="zoom:67%;" />

有的网站访问量大，需要负载均衡。然而并不是所有网站都如此出色，有的网站，由于访问量太小，需要节省成本，将多个网站部署在同一台服务器上。

例如将www.aaa.com和www.bbb.com两个网站部署在同一台服务器上，两个域名解析到同一个IP地址，但是用户通过两个域名却可以打开两个完全不同的网站，互相不影响，就像访问两个服务器一样，所以叫两个虚拟主机。

正向代理来进行上网等功能。

```
server {  
    listen 80 default_server;  
    server_name _;  
    return 444; # 过滤其他域名的请求，返回444状态码  
}  
 
server {  
    listen 80;  
    server_name www.aaa.com; # www.aaa.com域名  
    location / {  
        proxy_pass http://localhost:8080; # 对应端口号8080  
    }  
}  
server {  
    listen80;  
    server_name www.bbb.com; # www.bbb.com域名  
    location / {  
        proxy_pass http://localhost:8081; # 对应端口号8081  
    } 
}  
```

在服务器8080和8081分别开了一个应用，客户端通过不同的域名访问，根据server_name可以反向代理到对应的应用服务器。

虚拟主机的原理是通过HTTP请求头中的Host是否匹配server_name来实现的。

另外，server_name配置还可以过滤有人恶意将某些域名指向你的主机服务器。

## **反向代理**

<img src="/img/image-20220518072532385.png" alt="image-20220518072532385" style="zoom:67%;" />

客户端本来可以直接通过HTTP协议访问某网站应用服务器，网站管理员可以在中间加上一个Nginx，客户端请求Nginx，Nginx请求应用服务器，然后将结果返回给客户端，此时Nginx就是反向代理服务器。

客户端对代理服务器是无感知的，客户端不需要做任何配置，用户只请求反向代理服务器，反向代理服务器选择目标服务器，获取数据后再返回给客户端。反向代理服务器和目标服务器对外而言就是一个服务器，只是暴露的是代理服务器地址，而隐藏了真实服务器的IP地址。

```
server {  
    listen 80;  
    location / {  
        proxy_pass http://192.168.20.1:8080; # 应用服务器HTTP地址  
    }  
}  
```

## **负载均衡**

<img src="/img/image-20220518072550109.png" alt="image-20220518072550109" style="zoom:67%;" />

当网站访问量非常大，网站站长开心赚钱的同时，也摊上事儿了。因为网站越来越慢，一台服务器已经不够用了。于是将同一个应用部署在多台服务器上，将大量用户的请求分配给多台机器处理。同时带来的好处是，其中一台服务器万一挂了，只要还有其他服务器正常运行，就不会影响用户使用。

将原先请求集中到单个服务器上的情况改为增加服务器的数量，然后将请求分发到各个服务器上，将负载分发到不同的服务器，即负载均衡。

Nginx可以通过反向代理来实现负载均衡。

```
upstream myserver {   
    server 192.167.4.32:5000;
    server 192.168.4.32:8080;     
}           

server {     
    listen       80;   #监听端口   
    server_name  192.168.4.32;   #监听地址   
 
    location  / {             
        root html;  #html目录        
        index index.html index.htm;  #设置默认页    
        proxy_pass  http://myserver;  #请求转向 myserver 定义的服务器列表      
    }
} upstream myserver {   
    server 192.167.4.32:5000;
    server 192.168.4.32:8080;     
}           

server {     
    listen       80;   #监听端口   
    server_name  192.168.4.32;   #监听地址   
 
    location  / {             
        root html;  #html目录        
        index index.html index.htm;  #设置默认页    
        proxy_pass  http://myserver;  #请求转向 myserver 定义的服务器列表      
    }
} 
```

### 常用的4种nginx负载均衡算法

**1.轮询**

轮询是默认的方式，每个请求按时间顺序逐一分配到不同的后端服务器上。如果后台服务器上某一台宕机了，它可以自动剔除。

缺点：可靠性低和负载分配不均衡。适用于图片服务器和静态页面服务器集群。

**2. 加权轮询（wight）**

指定轮询的几率，wight和访问比率成正比，用于后台服务器性能不均匀的情况。

```
upstream linuxidc{       
   server 10.0.0.77 weight=5;       
   server 10.0.0.88 weight=10; 
}复制代码
```

**3. ip_hash**

根据每个请求的ip的hash结果分配，因此每个固定ip能访问到同一个后端服务器，可以解决session问题。

```
upstream favresin{      
    ip_hash;      
    server 10.0.0.10:8080;       
    server 10.0.0.11:8080; 
}复制代码
```

**4. fair（第三方）**

按照后端服务器的响应时间来分配请求，响应时间短的优先分配。

```
 upstream favresin{            
      server 10.0.0.10:8080;       
      server 10.0.0.11:8080;       
      fair; 
}复制代码
```

**5. url_hash（第三方）**

按照访问url的hash结果来分配请求，每个固定的url访问同一个后端服务器。如果后端服务器是缓存时效率高。

```
 upstream resinserver{       
      server 10.0.0.10:7777;       
      server 10.0.0.11:8888;       
      hash $request_uri;       
      hash_method crc32; 
}
例：在upstream中加入hash语句，hash_method是使用的hash算法。
复制代码
```

在upstream模块中，可以通过server命令指定后端服务器的IP地址和端口，同时还可以设置每台后端服务器在负载均衡调度中的状态，

**upstream参数解析**

- upstream可以为每个设备设置状态值
- down：表示当前的server暂时不参与负载
- weight：默认为1，wight越大，负载的权重越大。
- max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误。
- fail_timeout：max_fails此失败后，暂停的时间。
- backup：其他所有非backup机器宕或者忙的时候，请求backup的机器。

示例：

```
tips:
upstream bakend{ #定义负载均衡设备的Ip及设备状态  
  ip_hash;  
  server 192.0.0.1:8090 weight=5 max_fails=3 fail_timeout=20s;
  server 127.0.0.1:9090 down; 
  server 127.0.0.1:8080 weight=2;    
  server 127.0.0.1:6060;  
  server 127.0.0.1:7070 backup;  
}复制代码
```

### 常见的几种负载均衡算法

**1、轮询法**

将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。

**2、加权轮询法**

不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。

**3、随机法**

通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，

其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。

**4、加权随机法**

与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。

**5、哈希算法**

- 普通哈希：源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。
- 一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。一致性hash算法就是把每台server分成v个虚拟节点，再把所有虚拟节点（n*v）随机分配到一致性哈希的圆环上，这样所有的用户从自己圆环上的位置顺时针往下取到第一个vnode就是自己所属的节点。当此节点存在故障时，再顺时针取下一个作为替代节点

**6、最小连接数法**

最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前

积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。

**7、IP地址散列**

通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处理。

**8、URL散列**

通过管理客户端请求URL信息的散列，将发送至相同URL的请求转发至同一服务器的算法。

### 四层和七层负载均衡

四层负载均衡工作在OSI模型的**传输层**，主要工作是转发，它在接收到客户端的流量以后通过修改数据包的地址信息将流量转发到应用服务器。

七层负载均衡工作在OSI模型的**应用层**，因为它需要解析应用层流量，所以七层负载均衡在接到客户端的流量以后，还需要一个完整的TCP/IP协议栈。七层负载均衡会与客户端建立一条完整的连接并将应用层的请求流量解析出来，再按照调度算法选择一个应用服务器，并与应用服务器建立另外一条连接将请求发送过去，因此七层负载均衡的主要工作就是代理。

**软硬件**

1）四层的负载均衡就是基于IP+端口的负载均衡：

> 对应的负载均衡器称为四层交换机（L4 switch），主要分析IP层及TCP/UDP层，实现四层负载均衡。此种负载均衡器不理解应用协议（如HTTP/FTP/MySQL等等）。

**实现四层负载均衡的软件有：**

- F5：硬件负载均衡器，功能很好，但是成本很高。
- lvs：重量级的四层负载软件
- nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活
- haproxy：模拟四层转发，较灵活

2）七层的负载均衡就是基于虚拟的URL或主机IP的负载均衡

> 对应的负载均衡器称为七层交换机（L7 switch），除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息，实现七层负载均衡。此种负载均衡器能理解应用协议。

**实现七层负载均衡的软件有：**

- haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；
- nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；
- apache：功能较差
- Mysql proxy：功能尚可。

总的来说，一般是lvs做4层负载；nginx做7层负载；haproxy比较灵活，4层和7层负载均衡都能做。

**技术原理上的区别：**

所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

> 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。

<img src="/img/image-20220519072131243.png" alt="image-20220519072131243" style="zoom:67%;" />

所谓七层负载均衡，也称为“内容交换”，也就是主要通过**报文中的真正有意义的应用层内容**，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

> 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。

**具体实现：**

（1）目前负载均衡系统有Nginx、LVS、F5，即：

- Nginx是软件的7层负载均衡，
- LVS是内核的4层负载均衡，
- F5是硬件的4层负载均衡。

（2）软件和硬件的区别在于性能，硬件远远高于软件，即：

- Nginx的性能是万级的，一般的Linux服务器上安装一个Nginx能达到每秒5万并发请求；
- 而F5的性能能达到百万级，从200万每秒到800万每秒都有，不过价格很贵。

（3）4层和7层的区别在于协议和灵活性，即：

- Nginx是7层的，它支持HTTP等协议，
- 而LVS和F5是4层协议，它们和协议无关，几乎所有应用都可以做。



## 高可用

<img src="/img/image-20220518072705600.png" alt="image-20220518072705600" style="zoom:67%;" />

为了提高系统的可用性和容错能力，可以增加nginx服务器的数量，当主服务器发生故障或宕机，备份服务器可以立即充当主服务器进行不间断工作。

# 参考

[从原理到实战，彻底搞懂 Nginx！入门篇](https://zhuanlan.zhihu.com/p/101961241)

[从原理到实战，彻底搞懂 Nginx！中级篇](https://zhuanlan.zhihu.com/p/102528726)